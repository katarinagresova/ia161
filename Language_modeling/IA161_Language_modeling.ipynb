{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kópia zápisníka IA161-2021-Language-modeling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/katarinagresova/ia161/blob/main/IA161_Language_modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEg9l2Z51sm0"
      },
      "source": [
        "This notebook contains practical part of Language modeling lesson from Advanced NLP course. Goal is to train simple neural network based on word pairs and use it to generate new text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkWFruXL9_90"
      },
      "source": [
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import re"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wrY-8VYA9dS"
      },
      "source": [
        "# Data\n",
        "Books in plain text from Project Gutenberg\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSjUCa3dA946",
        "outputId": "ff598b6e-fd83-43a9-f6cc-c893942f04bd"
      },
      "source": [
        "!wget https://gutenberg.net.au/ebooks01/0100021.txt       # en 1984\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-29 09:18:29--  https://gutenberg.net.au/ebooks01/0100021.txt\n",
            "Resolving gutenberg.net.au (gutenberg.net.au)... 43.229.63.241\n",
            "Connecting to gutenberg.net.au (gutenberg.net.au)|43.229.63.241|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 598421 (584K) [text/plain]\n",
            "Saving to: ‘0100021.txt’\n",
            "\n",
            "0100021.txt         100%[===================>] 584.40K   606KB/s    in 1.0s    \n",
            "\n",
            "2021-09-29 09:18:31 (606 KB/s) - ‘0100021.txt’ saved [598421/598421]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqzxYgyiqGUT"
      },
      "source": [
        "## Tokenization\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aT7Hj51iBJSL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0ef625a-e923-40d9-bf5a-410fa989c46e"
      },
      "source": [
        "train_text = open(\"0100021.txt\").read()\n",
        "train_text = train_text.replace('\\n\\n','\\n<p>\\n')\n",
        "\n",
        "print(train_text[3000:3300])\n",
        "toks = train_text.split()\n",
        "toks[1000:1020]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " overalls\n",
            "which were the uniform of the party. His hair was very fair, his face\n",
            "naturally sanguine, his skin roughened by coarse soap and blunt razor\n",
            "blades and the cold of the winter that had just ended.\n",
            "<p>\n",
            "Outside, even through the shut window-pane, the world looked cold. Down in\n",
            "the street littl\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['willow-herb',\n",
              " 'straggled',\n",
              " 'over',\n",
              " 'the',\n",
              " 'heaps',\n",
              " 'of',\n",
              " 'rubble;',\n",
              " 'and',\n",
              " 'the',\n",
              " 'places',\n",
              " 'where',\n",
              " 'the',\n",
              " 'bombs',\n",
              " 'had',\n",
              " 'cleared',\n",
              " 'a',\n",
              " 'larger',\n",
              " 'patch',\n",
              " 'and',\n",
              " 'there']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usLfD8d9ptLK"
      },
      "source": [
        "# Neural Model\n",
        "\n",
        "[expit](https://docs.scipy.org/doc/scipy/reference/generated/scipy.special.expit.html) is the logistic sigmoid\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jg9Aj_Zjqp_U"
      },
      "source": [
        "from scipy.special import expit\n",
        "\n",
        "dim = 30\n",
        "neg_examples = 0"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jMDw8ll3jnT"
      },
      "source": [
        "`vocab` maps word ID to string, `w2id` maps a word to its ID, `wfrq` contains frequences of all words in `vocab`, `prob` contains respective probabilities\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyWX9yBUquFo",
        "outputId": "8f428dc4-c57f-4b8f-acd6-de78148e05e9"
      },
      "source": [
        "vocab = list(set(toks))\n",
        "w2id = {w:i for (i,w) in enumerate(vocab)}\n",
        "wfrq = np.zeros(len(vocab))\n",
        "tokIDs = [w2id[w] for w in toks]\n",
        "for id in tokIDs:\n",
        "  wfrq[id] += 1\n",
        "wprob = wfrq/sum(wfrq)\n",
        "print(len(vocab), w2id['a'], wfrq[w2id['a']], vocab[:4], wfrq[:4])\n",
        "print(len(toks), len(tokIDs), wprob)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15567 6781 2416.0 ['SHOULD', 'streams', 'twist', 'to-and-fro'] [1. 1. 6. 1.]\n",
            "104938 104938 [9.52943643e-06 9.52943643e-06 5.71766186e-05 ... 9.52943643e-05\n",
            " 9.52943643e-06 9.52943643e-06]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ul_FW7si4CT4"
      },
      "source": [
        "`node_vec` and `ctx_vec` are matrices containding a word embedding vector for each word\n",
        "\n",
        "We train them on pairs of words *(w1, w2)*, *w2* follows *w1*, an embedding of *w1* in `ctx_vec` should be close to an embedding of *w2* in `node_vec`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWNbBzDjsXTL"
      },
      "source": [
        "node_vec = np.random.rand(len(vocab), dim)\n",
        "ctx_vec = np.zeros((len(vocab), dim))\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8C4A5pBuvQ21",
        "outputId": "3301f5cd-470f-48ea-c700-c77755c9ce89"
      },
      "source": [
        "wfrq, len(wfrq)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 1.,  1.,  6., ..., 10.,  1.,  1.]), 15567)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpGcUV-3tX0x"
      },
      "source": [
        "def train_pair(nodeid, ctxid, alpha):\n",
        "  global node_vec, ctx_vec\n",
        "  L1 = node_vec[nodeid]\n",
        "  L2 = ctx_vec[ctxid]\n",
        "  corr = (1 - expit(np.dot(L2, L1)))* alpha\n",
        "  node_vec[nodeid] += corr * (L2 - L1)\n",
        "  ctx_vec[ctxid] += corr * (L1 - L2)\n",
        "  \n",
        "  if neg_examples == 0:\n",
        "    return\n",
        "  negs = np.random.choice(len(vocab), neg_examples, p=wprob)\n",
        "  L2n = ctx_vec[negs]\n",
        "  corrn = expit(np.dot(L2n, L1))* alpha\n",
        "  #node_vec[nodeid] += corr * (L2 - L1)\n",
        "  L2n += corr * (L2n - L1)\n",
        "\n",
        "\n",
        "def tranin_corpus(epochs=10, start_alpha=0.5):\n",
        "  parcnt = 0\n",
        "  last_parcnt = 0\n",
        "  parid = w2id['<p>']\n",
        "  total_parcnt = float(epochs * wfrq[parid])\n",
        "  alpha = start_alpha\n",
        "  \n",
        "  for e in range(epochs):\n",
        "    print('epoch:', e, 'paragraphs:', parcnt, 'alpha:', alpha)\n",
        "    last = tokIDs[0]\n",
        "    for wid in tokIDs[1:]:\n",
        "      if wid == parid:\n",
        "        parcnt += 1\n",
        "      train_pair(wid, last, alpha)\n",
        "      last = wid\n",
        "      if parcnt >= last_parcnt + 200:\n",
        "        a = start_alpha * (1 - parcnt/total_parcnt)\n",
        "        alpha = max(a, start_alpha * 0.0001)\n",
        "\n",
        "   "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWvc1IaPBEGP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1067b469-2633-4bfb-fe79-686730323fb5"
      },
      "source": [
        "tranin_corpus(100)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0 paragraphs: 0 alpha: 0.5\n",
            "epoch: 1 paragraphs: 1408 alpha: 0.49500354861603973\n",
            "epoch: 2 paragraphs: 2816 alpha: 0.49000709723207947\n",
            "epoch: 3 paragraphs: 4224 alpha: 0.48501064584811926\n",
            "epoch: 4 paragraphs: 5632 alpha: 0.480014194464159\n",
            "epoch: 5 paragraphs: 7040 alpha: 0.47501774308019873\n",
            "epoch: 6 paragraphs: 8448 alpha: 0.47002129169623846\n",
            "epoch: 7 paragraphs: 9856 alpha: 0.4650248403122782\n",
            "epoch: 8 paragraphs: 11264 alpha: 0.46002838892831793\n",
            "epoch: 9 paragraphs: 12672 alpha: 0.4550319375443577\n",
            "epoch: 10 paragraphs: 14080 alpha: 0.45003548616039746\n",
            "epoch: 11 paragraphs: 15488 alpha: 0.4450390347764372\n",
            "epoch: 12 paragraphs: 16896 alpha: 0.4400425833924769\n",
            "epoch: 13 paragraphs: 18304 alpha: 0.43504613200851666\n",
            "epoch: 14 paragraphs: 19712 alpha: 0.4300496806245564\n",
            "epoch: 15 paragraphs: 21120 alpha: 0.4250532292405962\n",
            "epoch: 16 paragraphs: 22528 alpha: 0.4200567778566359\n",
            "epoch: 17 paragraphs: 23936 alpha: 0.41506032647267566\n",
            "epoch: 18 paragraphs: 25344 alpha: 0.4100638750887154\n",
            "epoch: 19 paragraphs: 26752 alpha: 0.4050674237047551\n",
            "epoch: 20 paragraphs: 28160 alpha: 0.4000709723207949\n",
            "epoch: 21 paragraphs: 29568 alpha: 0.39507452093683465\n",
            "epoch: 22 paragraphs: 30976 alpha: 0.3900780695528744\n",
            "epoch: 23 paragraphs: 32384 alpha: 0.3850816181689141\n",
            "epoch: 24 paragraphs: 33792 alpha: 0.38008516678495385\n",
            "epoch: 25 paragraphs: 35200 alpha: 0.37508871540099364\n",
            "epoch: 26 paragraphs: 36608 alpha: 0.3700922640170333\n",
            "epoch: 27 paragraphs: 38016 alpha: 0.3650958126330731\n",
            "epoch: 28 paragraphs: 39424 alpha: 0.36009936124911285\n",
            "epoch: 29 paragraphs: 40832 alpha: 0.3551029098651526\n",
            "epoch: 30 paragraphs: 42240 alpha: 0.3501064584811924\n",
            "epoch: 31 paragraphs: 43648 alpha: 0.34511000709723205\n",
            "epoch: 32 paragraphs: 45056 alpha: 0.34011355571327184\n",
            "epoch: 33 paragraphs: 46464 alpha: 0.3351171043293116\n",
            "epoch: 34 paragraphs: 47872 alpha: 0.3301206529453513\n",
            "epoch: 35 paragraphs: 49280 alpha: 0.32512420156139105\n",
            "epoch: 36 paragraphs: 50688 alpha: 0.3201277501774308\n",
            "epoch: 37 paragraphs: 52096 alpha: 0.31513129879347057\n",
            "epoch: 38 paragraphs: 53504 alpha: 0.31013484740951025\n",
            "epoch: 39 paragraphs: 54912 alpha: 0.30513839602555004\n",
            "epoch: 40 paragraphs: 56320 alpha: 0.3001419446415898\n",
            "epoch: 41 paragraphs: 57728 alpha: 0.2951454932576295\n",
            "epoch: 42 paragraphs: 59136 alpha: 0.2901490418736693\n",
            "epoch: 43 paragraphs: 60544 alpha: 0.285152590489709\n",
            "epoch: 44 paragraphs: 61952 alpha: 0.28015613910574877\n",
            "epoch: 45 paragraphs: 63360 alpha: 0.2751596877217885\n",
            "epoch: 46 paragraphs: 64768 alpha: 0.27016323633782824\n",
            "epoch: 47 paragraphs: 66176 alpha: 0.26516678495386803\n",
            "epoch: 48 paragraphs: 67584 alpha: 0.2601703335699077\n",
            "epoch: 49 paragraphs: 68992 alpha: 0.2551738821859475\n",
            "epoch: 50 paragraphs: 70400 alpha: 0.25017743080198723\n",
            "epoch: 51 paragraphs: 71808 alpha: 0.24518097941802697\n",
            "epoch: 52 paragraphs: 73216 alpha: 0.2401845280340667\n",
            "epoch: 53 paragraphs: 74624 alpha: 0.23518807665010644\n",
            "epoch: 54 paragraphs: 76032 alpha: 0.23019162526614623\n",
            "epoch: 55 paragraphs: 77440 alpha: 0.22519517388218596\n",
            "epoch: 56 paragraphs: 78848 alpha: 0.2201987224982257\n",
            "epoch: 57 paragraphs: 80256 alpha: 0.21520227111426543\n",
            "epoch: 58 paragraphs: 81664 alpha: 0.21020581973030517\n",
            "epoch: 59 paragraphs: 83072 alpha: 0.2052093683463449\n",
            "epoch: 60 paragraphs: 84480 alpha: 0.2002129169623847\n",
            "epoch: 61 paragraphs: 85888 alpha: 0.19521646557842443\n",
            "epoch: 62 paragraphs: 87296 alpha: 0.19022001419446416\n",
            "epoch: 63 paragraphs: 88704 alpha: 0.1852235628105039\n",
            "epoch: 64 paragraphs: 90112 alpha: 0.18022711142654363\n",
            "epoch: 65 paragraphs: 91520 alpha: 0.17523066004258342\n",
            "epoch: 66 paragraphs: 92928 alpha: 0.17023420865862315\n",
            "epoch: 67 paragraphs: 94336 alpha: 0.1652377572746629\n",
            "epoch: 68 paragraphs: 95744 alpha: 0.16024130589070262\n",
            "epoch: 69 paragraphs: 97152 alpha: 0.15524485450674236\n",
            "epoch: 70 paragraphs: 98560 alpha: 0.1502484031227821\n",
            "epoch: 71 paragraphs: 99968 alpha: 0.14525195173882188\n",
            "epoch: 72 paragraphs: 101376 alpha: 0.14025550035486162\n",
            "epoch: 73 paragraphs: 102784 alpha: 0.13525904897090135\n",
            "epoch: 74 paragraphs: 104192 alpha: 0.1302625975869411\n",
            "epoch: 75 paragraphs: 105600 alpha: 0.12526614620298082\n",
            "epoch: 76 paragraphs: 107008 alpha: 0.12026969481902056\n",
            "epoch: 77 paragraphs: 108416 alpha: 0.11527324343506035\n",
            "epoch: 78 paragraphs: 109824 alpha: 0.11027679205110008\n",
            "epoch: 79 paragraphs: 111232 alpha: 0.10528034066713982\n",
            "epoch: 80 paragraphs: 112640 alpha: 0.10028388928317955\n",
            "epoch: 81 paragraphs: 114048 alpha: 0.09528743789921928\n",
            "epoch: 82 paragraphs: 115456 alpha: 0.09029098651525908\n",
            "epoch: 83 paragraphs: 116864 alpha: 0.08529453513129881\n",
            "epoch: 84 paragraphs: 118272 alpha: 0.08029808374733854\n",
            "epoch: 85 paragraphs: 119680 alpha: 0.07530163236337828\n",
            "epoch: 86 paragraphs: 121088 alpha: 0.07030518097941801\n",
            "epoch: 87 paragraphs: 122496 alpha: 0.06530872959545775\n",
            "epoch: 88 paragraphs: 123904 alpha: 0.06031227821149754\n",
            "epoch: 89 paragraphs: 125312 alpha: 0.05531582682753727\n",
            "epoch: 90 paragraphs: 126720 alpha: 0.05031937544357701\n",
            "epoch: 91 paragraphs: 128128 alpha: 0.04532292405961674\n",
            "epoch: 92 paragraphs: 129536 alpha: 0.04032647267565648\n",
            "epoch: 93 paragraphs: 130944 alpha: 0.03533002129169621\n",
            "epoch: 94 paragraphs: 132352 alpha: 0.030333569907736002\n",
            "epoch: 95 paragraphs: 133760 alpha: 0.025337118523775737\n",
            "epoch: 96 paragraphs: 135168 alpha: 0.02034066713981547\n",
            "epoch: 97 paragraphs: 136576 alpha: 0.015344215755855206\n",
            "epoch: 98 paragraphs: 137984 alpha: 0.01034776437189494\n",
            "epoch: 99 paragraphs: 139392 alpha: 0.005351312987934731\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBAtQsF-135Y"
      },
      "source": [
        "### Similarity function\n",
        "find most similar words for the given one, it finds the most probable following word with default `src` and `tar` parameters \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDX_1_ia30QA"
      },
      "source": [
        " def sims(word, maxitems=5, src=None, tar=None):\n",
        "   if src is None:\n",
        "     src = ctx_vec\n",
        "   if tar is None:\n",
        "     tar = node_vec\n",
        "   wid = w2id[word]\n",
        "      \n",
        "   norms = np.linalg.norm(tar, axis=1)\n",
        "   L1 = src[wid]\n",
        "   allsims = np.dot(tar, L1)\n",
        "   allsims /= norms\n",
        "   allsims /= np.linalg.norm(L1)\n",
        "   top = np.argpartition(allsims, len(allsims) - maxitems -1)[-maxitems -1:]\n",
        "   top = [i for i in top if i != wid]\n",
        "   top.sort(key=lambda i:allsims[i], reverse=True)\n",
        "   return [(vocab[i], round(allsims[i],3)) for i in top]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bF5BDZrLBC1Z",
        "outputId": "37efc5b2-ee04-4794-80ee-ce9627cab0af"
      },
      "source": [
        "# print following words\n",
        "for w in 'Brother Big he she said is'.split():\n",
        "  print(w, sims(w))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Brother [(\"exist?'\", 1.0), ('swam', 1.0), ('is', 1.0), ('might', 1.0), ('must', 1.0), ('was', 1.0)]\n",
            "Big [('Brother', 1.0), ('Brother.', 0.998), ('Brother,', 0.991), ('money', 0.982), (\"'Thoughtcrime\", 0.981), ('invincible.', 0.98)]\n",
            "he [('said.', 1.0), ('said,', 1.0), ('could', 1.0), ('added', 1.0), ('had', 1.0), ('might', 1.0)]\n",
            "she [('added.', 1.0), ('said,', 1.0), ('might', 1.0), ('had', 1.0), ('was', 1.0), ('would', 1.0)]\n",
            "said [(\"O'Brien.\", 1.0), (\"O'Brien,\", 1.0), ('earlier,', 1.0), ('Syme.', 1.0), ('finally.', 1.0), ('those', 1.0)]\n",
            "is [('perfectly', 1.0), ('happening', 1.0), ('impossible.', 1.0), ('required', 1.0), ('whatever', 1.0), ('like.', 1.0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UiKKOEoTcOj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd13ebe4-e6bc-475c-b9e0-2ee5e303a466"
      },
      "source": [
        "# print similar words\n",
        "for w in 'she small years'.split():\n",
        "  print(w, sims(w, 5, node_vec, node_vec))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "she [('he', 1.0), ('they', 1.0), ('tomorrow', 1.0), ('it', 1.0), (\"I'd\", 1.0)]\n",
            "small [('little', 1.0), ('curious', 1.0), ('sort', 1.0), ('long', 1.0), ('tiny', 1.0)]\n",
            "years [(\"years.'\", 1.0), ('times', 1.0), ('mixed', 1.0), ('nineteen-thirty.', 1.0), ('reading', 1.0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dq0k5rFmDfxQ"
      },
      "source": [
        "import random\n",
        "\n",
        "def generate_text(seed='We', words=20):\n",
        "  text = seed\n",
        "\n",
        "  for _ in range(words):\n",
        "    next_words = sims(seed)\n",
        "    selected_word = random.choice(next_words)[0]\n",
        "    text += \" \" + selected_word\n",
        "    seed = selected_word\n",
        "\n",
        "  return text"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzFZ1OM4DoIf",
        "outputId": "41de1e85-0383-4938-93c8-8b1ee73b47ac"
      },
      "source": [
        "print(generate_text('We'))\n",
        "print(generate_text('We'))\n",
        "print(generate_text('We'))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We didn't ought afterwards. Three because he might bound afterwards. 'Did we shall meet again.' <p> 'We must start now, he\n",
            "We may mostly concretely, no, his own. 'What happens afterwards. 'We should intelligence, engaged permanently. Only----! 'God aroused now, he had\n",
            "We imagine angry leaders just away, outwards from the Thought Police became pugnaciously. YOUR general, Eurasia i sub-section, here, tomorrow night,\n"
          ]
        }
      ]
    }
  ]
}