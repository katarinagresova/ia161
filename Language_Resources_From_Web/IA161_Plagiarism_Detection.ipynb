{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IA161_Plagiarism Detection.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyODwog2erbsbIYWShNSXwrD"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFgPpCOIaFdu"
      },
      "source": [
        "## Plagiarism Detection\n",
        "\n",
        "### Main and related tasks in plagiarism detection\n",
        "\n",
        "* **Plagiarism detection:** Given a document, identify all  plagiarized sources and boundaries of re-used passages.\n",
        "   - similar to deduplication\n",
        "* **Author identification:** Given a document, identify its author.\n",
        "* **Author profiling:** Given a document, extract information about the author (e.g. gender, age).\n",
        "\n",
        "### External vs. Intrinsic plagiarism detection\n",
        "\n",
        "#### External plagiarism detection\n",
        "\n",
        "Given a set of suspicious documents and a set of source documents the\n",
        "task is to find all text passages in the suspicious documents which have\n",
        "been plagiarized and the corresponding text passages in the source\n",
        "documents.\n",
        "\n",
        "#### Intrinsic plagiarism detection\n",
        "\n",
        "Given a set of suspicious documents the task is to identify all plagiarized\n",
        "text passages, e.g., by detecting writing style breaches. The comparison of\n",
        "a suspicious document with other documents is not allowed in this task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzVGtYJ9tIjU"
      },
      "source": [
        "# Task: Select a detection algorithm and implement it in Python\n",
        "\n",
        "- Input: File in a 3-column vertical format (word, lemma, tag)\n",
        "- Output: One plagiarism per line: id TAB detected source id TAB real source id. Evaluation line: precision, recall F1 measure.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3pRAJqQw3sK",
        "outputId": "ded2a38c-fee8-4b3a-945d-a52a7a02ad23"
      },
      "source": [
        "!wget https://nlp.fi.muni.cz/trac/research/raw-attachment/wiki/en/AdvancedNlpCourse/LanguageResourcesFromWeb/training_data.vert"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-02 16:24:16--  https://nlp.fi.muni.cz/trac/research/raw-attachment/wiki/en/AdvancedNlpCourse/LanguageResourcesFromWeb/training_data.vert\n",
            "Resolving nlp.fi.muni.cz (nlp.fi.muni.cz)... 147.251.51.11\n",
            "Connecting to nlp.fi.muni.cz (nlp.fi.muni.cz)|147.251.51.11|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 Ok\n",
            "Length: 503730 (492K) [application/octet-stream]\n",
            "Saving to: ‘training_data.vert’\n",
            "\n",
            "training_data.vert  100%[===================>] 491.92K   922KB/s    in 0.5s    \n",
            "\n",
            "2021-11-02 16:24:18 (922 KB/s) - ‘training_data.vert’ saved [503730/503730]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYTkz1JtVo68"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import spatial\n",
        "import re\n",
        "\n",
        "class PlagiarismDetector:\n",
        "\n",
        "  def __init__(self):\n",
        "    self.metadata = None\n",
        "    self.docs = None\n",
        "\n",
        "    self.doc_similarity_threshold = 0.5\n",
        "\n",
        "    # store computations that might be useful for other methods\n",
        "    self.bag_of_words_docs = None\n",
        "    self.doc_counts_per_word = None\n",
        "\n",
        "  def parse_input(self, vert_file):\n",
        "    \"\"\"\n",
        "    Parse input vert file into two dictionaries - metadata and docs. \n",
        "    On top level, metagata group documents by authors. Each author has two lists of documents:\n",
        "      - original\n",
        "      - suspicious\n",
        "    Each document metadata is represented by dictionary with keys:\n",
        "      - author, \n",
        "      - unique id, \n",
        "      - class (original or suspicious), \n",
        "      - source_id (The same as unique id for originals. Referencing original unique id for suspicious documents.),\n",
        "    Second dictionary - docs - is organized by document id (referencing unique id from metadata).\n",
        "    Each document is represented by pandas DataFrame with three columns:\n",
        "      - word\n",
        "      - lemma\n",
        "      - tag\n",
        "    \"\"\"\n",
        "\n",
        "    header_re = re.compile('<doc author=\"([^\"]+)\" id=\"(\\d+)\" class=\"(plagiarism|original)\" source=\"(\\d+)\"')\n",
        "    self.metadata = {}\n",
        "    self.docs = {}\n",
        "    current_id = None\n",
        "    doc_list = []\n",
        "\n",
        "    with open(vert_file, \"r\") as handle:\n",
        "      for line in handle:\n",
        "\n",
        "        # start of the document - preparing metadata\n",
        "        if line.startswith('<doc'):\n",
        "\n",
        "          # structure for info about document\n",
        "          author, id_, class_, source_id = header_re.match(line).groups()\n",
        "          doc = {\n",
        "            'author': author,\n",
        "            'id': id_,\n",
        "            'class': class_,\n",
        "            'source_id': source_id,\n",
        "          }\n",
        "          current_id = id_\n",
        "          doc_list = []\n",
        "\n",
        "        # end of the document - storing metadata\n",
        "        elif line.startswith('</doc'):\n",
        "\n",
        "          # adding document to author's set - to original of suspisious documents\n",
        "          if not doc['author'] in self.metadata:\n",
        "              self.metadata[doc['author']] = {'original': [], 'suspicious': []}\n",
        "          if doc['class'] == 'original':\n",
        "              self.metadata[doc['author']]['original'].append(doc)\n",
        "          else:\n",
        "              self.metadata[doc['author']]['suspicious'].append(doc)\n",
        "\n",
        "          self.docs[current_id] = pd.DataFrame(doc_list, columns=['word', 'lemma', 'tag'])\n",
        "\n",
        "        elif not line.startswith('<'):\n",
        "\n",
        "          # storing content of document\n",
        "          word, lemma, tag = line.rstrip().split('\\t')[:3]\n",
        "          doc_list.append([word, lemma, tag])\n",
        "\n",
        "  def length_removal(self, min_length):\n",
        "\n",
        "    for id_, doc in self.docs.items():\n",
        "      self.docs[id_] = doc[doc['word'].map(len) >= min_length]\n",
        "\n",
        "  def bag_of_words(self, doc1_id, doc2_id, column):\n",
        "    if self.bag_of_words_docs == None:\n",
        "      self._precompute_bag_of_words_docs()\n",
        "\n",
        "    vectors = [[], []]\n",
        "    docs = [\n",
        "      self.bag_of_words_docs[doc1_id][column],\n",
        "      self.bag_of_words_docs[doc2_id][column]\n",
        "    ]\n",
        "    all_words = list(docs[0].keys() | docs[1].keys())\n",
        "  \n",
        "    for doc_index in [0, 1]:\n",
        "      doc_len = float(sum(docs[doc_index].values()))\n",
        "\n",
        "      for word in all_words:\n",
        "        vectors[doc_index].append(docs[doc_index].get(word, 0) / doc_len)\n",
        "\n",
        "    cosine_similarity = 1.0 - spatial.distance.cosine(vectors[0], vectors[1])\n",
        "    return cosine_similarity\n",
        "\n",
        "  def _precompute_bag_of_words_docs(self):\n",
        "    self.bag_of_words_docs = {}\n",
        "\n",
        "    for id_, doc in self.docs.items():\n",
        "      self.bag_of_words_docs[id_] = {}\n",
        "      for column in ['word', 'lemma', 'tag']:\n",
        "        self.bag_of_words_docs[id_][column] = {}\n",
        "        for word in doc[column]:\n",
        "          self.bag_of_words_docs[id_][column][word] = self.bag_of_words_docs[id_][column].get(word, 0) + 1\n",
        "\n",
        "  def _tf(self, word, doc_id, column):\n",
        "\n",
        "    try:\n",
        "      num_of_words = float(sum(self.bag_of_words_docs[doc_id][column].values()))\n",
        "      # count of word in current document / count of all words in document\n",
        "      return self.bag_of_words_docs[doc_id][column][word]/num_of_words\n",
        "    except:\n",
        "      return 0\n",
        "\n",
        "  def _precompute_doc_counts_per_word(self):\n",
        "\n",
        "    if self.bag_of_words_docs is None:\n",
        "      self._precompute_bag_of_words_docs()\n",
        "\n",
        "    self.doc_counts_per_word = {}\n",
        "    \n",
        "    for id_, doc in self.bag_of_words_docs.items():\n",
        "      for column in ['word', 'lemma', 'tag']:\n",
        "        self.doc_counts_per_word[column] = {}\n",
        "        for word in doc[column]:\n",
        "          self.doc_counts_per_word[column][word] = self.doc_counts_per_word[column].get(word, 0) + 1\n",
        "\n",
        "  def _idf(self,word, column):\n",
        "\n",
        "    num_of_docs = len(self.docs)\n",
        "\n",
        "    try:\n",
        "      word_occurance = self.doc_counts_per_word[word] + 1\n",
        "    except:\n",
        "      word_occurance = 1\n",
        "    return np.log(num_of_docs/word_occurance)\n",
        "\n",
        "  def _tf_idf_doc(self, doc_id, column):\n",
        "\n",
        "    if self.doc_counts_per_word is None:\n",
        "      self._precompute_doc_counts_per_word()\n",
        "\n",
        "    tf_idf_vec = np.zeros((len(self.doc_counts_per_word[column]),))\n",
        "    for index, word in enumerate(self.doc_counts_per_word[column].keys()):\n",
        "      tf = self._tf(word, doc_id, column)\n",
        "      idf = self._idf(word, column)\n",
        "        \n",
        "      value = tf*idf\n",
        "      tf_idf_vec[index] = value \n",
        "    return tf_idf_vec\n",
        "\n",
        "  def tf_idf(self, doc1_id, doc2_id, column): \n",
        "\n",
        "    vector1 = self._tf_idf_doc(doc1_id, column)\n",
        "    vector2 = self._tf_idf_doc(doc2_id, column)\n",
        "    cosine_similarity = 1.0 - spatial.distance.cosine(vector1, vector2)\n",
        "    return cosine_similarity\n",
        "\n",
        "\n",
        "  def get_all_metrics(self):\n",
        "    return [self.bag_of_words, self.tf_idf]\n",
        "\n",
        "  def _compute_stats(self, stats):\n",
        "    try:\n",
        "      precision = stats['tp'] / float(stats['tp'] + stats['fp'])\n",
        "    except ZeroDivisionError:\n",
        "      precision = 0.0\n",
        "    try:\n",
        "      recall = stats['tp'] / float(stats['tp'] + stats['fn'])\n",
        "    except ZeroDivisionError:\n",
        "      recall = 0.0\n",
        "    try:\n",
        "      f1_measure = 2 * precision * recall / (precision + recall)\n",
        "    except ZeroDivisionError:\n",
        "      f1_measure = 0.0\n",
        "\n",
        "    return precision, recall, f1_measure\n",
        "\n",
        "  def evaluate(self, metrics=None):\n",
        "\n",
        "    if metrics is None:\n",
        "      metrics = self.get_all_metrics()\n",
        "\n",
        "    for metric in metrics:\n",
        "      for column in ['word', 'lemma', 'tag']:\n",
        "        stats = {'tp': 0, 'fp': 0, 'tn': 0, 'fn': 0}\n",
        "\n",
        "        for author, doc_set in self.metadata.items():\n",
        "          set_stats = {'tp': 0, 'fp': 0, 'tn': 0, 'fn': 0}\n",
        "          for doc in doc_set['suspicious']:\n",
        "\n",
        "            most_similar_doc_id = doc['id'] # default: document is most similar to itself\n",
        "            highest_similarity_score = 0.0\n",
        "            for orig_doc in doc_set['original']:\n",
        "\n",
        "              similarity_score = metric(doc1_id=doc['id'], doc2_id=orig_doc['id'], column=column)\n",
        "              if similarity_score >= self.doc_similarity_threshold \\\n",
        "                      and similarity_score > highest_similarity_score:\n",
        "                  most_similar_doc_id = orig_doc['id']\n",
        "                  highest_similarity_score = similarity_score\n",
        "\n",
        "            if most_similar_doc_id == doc['source_id']:\n",
        "              if doc['class'] == 'plagiarism':\n",
        "                stats['tp'] += 1\n",
        "              else:\n",
        "                stats['tn'] += 1\n",
        "            else:\n",
        "              if doc['class'] == 'plagiarism':\n",
        "                stats['fp'] += 1\n",
        "              else:\n",
        "                stats['fn'] += 1\n",
        "\n",
        "        precision, recall, f1_measure = self._compute_stats(stats)\n",
        "        print('Overall precision: %.2f, recall: %.2f, F1: %.2f \\nfor method %s and column %s\\n' %\n",
        "          (precision, recall, f1_measure, metric, column))\n",
        "        \n",
        "  def set_doc_similarity_threshold(self, threshold):\n",
        "    self.doc_similarity_threshold = threshold"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mu0OfiHJYz1w"
      },
      "source": [
        "detector = PlagiarismDetector()\n",
        "detector.parse_input('training_data.vert')"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nrnlox6RZQTl"
      },
      "source": [
        "detector.length_removal(3)"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2r2LctY0E8d",
        "outputId": "7ef2582a-d47b-49d2-b7d7-0415cc0294b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "detector.set_doc_similarity_threshold(-1)\n",
        "detector.evaluate()"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall precision: 0.90, recall: 1.00, F1: 0.95 \n",
            "for method <bound method PlagiarismDetector.bag_of_words of <__main__.PlagiarismDetector object at 0x7f8663daac90>> and column word\n",
            "\n",
            "Overall precision: 0.88, recall: 1.00, F1: 0.93 \n",
            "for method <bound method PlagiarismDetector.bag_of_words of <__main__.PlagiarismDetector object at 0x7f8663daac90>> and column lemma\n",
            "\n",
            "Overall precision: 0.88, recall: 1.00, F1: 0.93 \n",
            "for method <bound method PlagiarismDetector.bag_of_words of <__main__.PlagiarismDetector object at 0x7f8663daac90>> and column tag\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/spatial/distance.py:720: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall precision: 0.65, recall: 1.00, F1: 0.79 \n",
            "for method <bound method PlagiarismDetector.tf_idf of <__main__.PlagiarismDetector object at 0x7f8663daac90>> and column word\n",
            "\n",
            "Overall precision: 0.70, recall: 1.00, F1: 0.82 \n",
            "for method <bound method PlagiarismDetector.tf_idf of <__main__.PlagiarismDetector object at 0x7f8663daac90>> and column lemma\n",
            "\n",
            "Overall precision: 0.78, recall: 1.00, F1: 0.87 \n",
            "for method <bound method PlagiarismDetector.tf_idf of <__main__.PlagiarismDetector object at 0x7f8663daac90>> and column tag\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7s-j_hmh0CUy",
        "outputId": "c492ebf3-b5c8-4cee-c4cb-20278eadda83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "detector.set_doc_similarity_threshold(0.01)\n",
        "detector.evaluate()"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall precision: 0.90, recall: 1.00, F1: 0.95 \n",
            "for method <bound method PlagiarismDetector.bag_of_words of <__main__.PlagiarismDetector object at 0x7f8663daac90>> and column word\n",
            "\n",
            "Overall precision: 0.88, recall: 1.00, F1: 0.93 \n",
            "for method <bound method PlagiarismDetector.bag_of_words of <__main__.PlagiarismDetector object at 0x7f8663daac90>> and column lemma\n",
            "\n",
            "Overall precision: 0.88, recall: 1.00, F1: 0.93 \n",
            "for method <bound method PlagiarismDetector.bag_of_words of <__main__.PlagiarismDetector object at 0x7f8663daac90>> and column tag\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/spatial/distance.py:720: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall precision: 0.65, recall: 1.00, F1: 0.79 \n",
            "for method <bound method PlagiarismDetector.tf_idf of <__main__.PlagiarismDetector object at 0x7f8663daac90>> and column word\n",
            "\n",
            "Overall precision: 0.70, recall: 1.00, F1: 0.82 \n",
            "for method <bound method PlagiarismDetector.tf_idf of <__main__.PlagiarismDetector object at 0x7f8663daac90>> and column lemma\n",
            "\n",
            "Overall precision: 0.78, recall: 1.00, F1: 0.87 \n",
            "for method <bound method PlagiarismDetector.tf_idf of <__main__.PlagiarismDetector object at 0x7f8663daac90>> and column tag\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5Oco-goz8xh",
        "outputId": "52e608fd-2ffa-4745-e428-bffea4bd7231",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "detector.set_doc_similarity_threshold(0.05)\n",
        "detector.evaluate()"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall precision: 0.90, recall: 1.00, F1: 0.95 \n",
            "for method <bound method PlagiarismDetector.bag_of_words of <__main__.PlagiarismDetector object at 0x7f8663daac90>> and column word\n",
            "\n",
            "Overall precision: 0.88, recall: 1.00, F1: 0.93 \n",
            "for method <bound method PlagiarismDetector.bag_of_words of <__main__.PlagiarismDetector object at 0x7f8663daac90>> and column lemma\n",
            "\n",
            "Overall precision: 0.88, recall: 1.00, F1: 0.93 \n",
            "for method <bound method PlagiarismDetector.bag_of_words of <__main__.PlagiarismDetector object at 0x7f8663daac90>> and column tag\n",
            "\n",
            "Overall precision: 0.65, recall: 1.00, F1: 0.79 \n",
            "for method <bound method PlagiarismDetector.tf_idf of <__main__.PlagiarismDetector object at 0x7f8663daac90>> and column word\n",
            "\n",
            "Overall precision: 0.70, recall: 1.00, F1: 0.82 \n",
            "for method <bound method PlagiarismDetector.tf_idf of <__main__.PlagiarismDetector object at 0x7f8663daac90>> and column lemma\n",
            "\n",
            "Overall precision: 0.78, recall: 1.00, F1: 0.87 \n",
            "for method <bound method PlagiarismDetector.tf_idf of <__main__.PlagiarismDetector object at 0x7f8663daac90>> and column tag\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/spatial/distance.py:720: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aI-d8XvVz5av",
        "outputId": "dba4cecb-19b8-4fc3-e789-7eaa7724729e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "detector.set_doc_similarity_threshold(0.1)\n",
        "detector.evaluate()"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall precision: 0.90, recall: 1.00, F1: 0.95 \n",
            "for method <bound method PlagiarismDetector.bag_of_words of <__main__.PlagiarismDetector object at 0x7f8663daac90>> and column word\n",
            "\n",
            "Overall precision: 0.88, recall: 1.00, F1: 0.93 \n",
            "for method <bound method PlagiarismDetector.bag_of_words of <__main__.PlagiarismDetector object at 0x7f8663daac90>> and column lemma\n",
            "\n",
            "Overall precision: 0.88, recall: 1.00, F1: 0.93 \n",
            "for method <bound method PlagiarismDetector.bag_of_words of <__main__.PlagiarismDetector object at 0x7f8663daac90>> and column tag\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/spatial/distance.py:720: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall precision: 0.65, recall: 1.00, F1: 0.79 \n",
            "for method <bound method PlagiarismDetector.tf_idf of <__main__.PlagiarismDetector object at 0x7f8663daac90>> and column word\n",
            "\n",
            "Overall precision: 0.70, recall: 1.00, F1: 0.82 \n",
            "for method <bound method PlagiarismDetector.tf_idf of <__main__.PlagiarismDetector object at 0x7f8663daac90>> and column lemma\n",
            "\n",
            "Overall precision: 0.78, recall: 1.00, F1: 0.87 \n",
            "for method <bound method PlagiarismDetector.tf_idf of <__main__.PlagiarismDetector object at 0x7f8663daac90>> and column tag\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHQXJgYjltTB",
        "outputId": "bc1f1874-92ff-487a-9cb0-c0189032d46c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "detector.set_doc_similarity_threshold(0.2)\n",
        "detector.evaluate()"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall precision: 0.85, recall: 1.00, F1: 0.92 \n",
            "for method <bound method PlagiarismDetector.bag_of_words of <__main__.PlagiarismDetector object at 0x7f8663daac90>> and column word\n",
            "\n",
            "Overall precision: 0.88, recall: 1.00, F1: 0.93 \n",
            "for method <bound method PlagiarismDetector.bag_of_words of <__main__.PlagiarismDetector object at 0x7f8663daac90>> and column lemma\n",
            "\n",
            "Overall precision: 0.88, recall: 1.00, F1: 0.93 \n",
            "for method <bound method PlagiarismDetector.bag_of_words of <__main__.PlagiarismDetector object at 0x7f8663daac90>> and column tag\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/spatial/distance.py:720: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall precision: 0.62, recall: 1.00, F1: 0.77 \n",
            "for method <bound method PlagiarismDetector.tf_idf of <__main__.PlagiarismDetector object at 0x7f8663daac90>> and column word\n",
            "\n",
            "Overall precision: 0.70, recall: 1.00, F1: 0.82 \n",
            "for method <bound method PlagiarismDetector.tf_idf of <__main__.PlagiarismDetector object at 0x7f8663daac90>> and column lemma\n",
            "\n",
            "Overall precision: 0.78, recall: 1.00, F1: 0.87 \n",
            "for method <bound method PlagiarismDetector.tf_idf of <__main__.PlagiarismDetector object at 0x7f8663daac90>> and column tag\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqhcnzGzzZET",
        "outputId": "c3d1c018-a180-4ecc-bc88-07aba9cc29b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "detector.set_doc_similarity_threshold(0.3)\n",
        "detector.evaluate()"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall precision: 0.78, recall: 1.00, F1: 0.87 \n",
            "for method <bound method PlagiarismDetector.bag_of_words of <__main__.PlagiarismDetector object at 0x7f8663daac90>> and column word\n",
            "\n",
            "Overall precision: 0.88, recall: 1.00, F1: 0.93 \n",
            "for method <bound method PlagiarismDetector.bag_of_words of <__main__.PlagiarismDetector object at 0x7f8663daac90>> and column lemma\n",
            "\n",
            "Overall precision: 0.88, recall: 1.00, F1: 0.93 \n",
            "for method <bound method PlagiarismDetector.bag_of_words of <__main__.PlagiarismDetector object at 0x7f8663daac90>> and column tag\n",
            "\n",
            "Overall precision: 0.62, recall: 1.00, F1: 0.77 \n",
            "for method <bound method PlagiarismDetector.tf_idf of <__main__.PlagiarismDetector object at 0x7f8663daac90>> and column word\n",
            "\n",
            "Overall precision: 0.70, recall: 1.00, F1: 0.82 \n",
            "for method <bound method PlagiarismDetector.tf_idf of <__main__.PlagiarismDetector object at 0x7f8663daac90>> and column lemma\n",
            "\n",
            "Overall precision: 0.78, recall: 1.00, F1: 0.87 \n",
            "for method <bound method PlagiarismDetector.tf_idf of <__main__.PlagiarismDetector object at 0x7f8663daac90>> and column tag\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/spatial/distance.py:720: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tITOO3CK0Yae",
        "outputId": "d9430c26-0076-47ec-c69d-31dbd448d37c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "detector.set_doc_similarity_threshold(0.9)\n",
        "detector.evaluate()"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall precision: 0.17, recall: 1.00, F1: 0.30 \n",
            "for method <bound method PlagiarismDetector.bag_of_words of <__main__.PlagiarismDetector object at 0x7f8663daac90>> and column word\n",
            "\n",
            "Overall precision: 0.25, recall: 1.00, F1: 0.40 \n",
            "for method <bound method PlagiarismDetector.bag_of_words of <__main__.PlagiarismDetector object at 0x7f8663daac90>> and column lemma\n",
            "\n",
            "Overall precision: 0.47, recall: 1.00, F1: 0.64 \n",
            "for method <bound method PlagiarismDetector.bag_of_words of <__main__.PlagiarismDetector object at 0x7f8663daac90>> and column tag\n",
            "\n",
            "Overall precision: 0.28, recall: 1.00, F1: 0.43 \n",
            "for method <bound method PlagiarismDetector.tf_idf of <__main__.PlagiarismDetector object at 0x7f8663daac90>> and column word\n",
            "\n",
            "Overall precision: 0.33, recall: 1.00, F1: 0.49 \n",
            "for method <bound method PlagiarismDetector.tf_idf of <__main__.PlagiarismDetector object at 0x7f8663daac90>> and column lemma\n",
            "\n",
            "Overall precision: 0.42, recall: 1.00, F1: 0.60 \n",
            "for method <bound method PlagiarismDetector.tf_idf of <__main__.PlagiarismDetector object at 0x7f8663daac90>> and column tag\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/spatial/distance.py:720: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
          ]
        }
      ]
    }
  ]
}