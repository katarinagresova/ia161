{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BiLSTM & FastText NER",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/katarinagresova/ia161/blob/main/Named_Entity_Recognition/IA161_Named_Entity_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2KQq6Ghv4HI"
      },
      "source": [
        "# Named Entity Recognition for Czech with Neural Networks and Pretrained Word Embeddings\n",
        "\n",
        "In this session, we will train our own named entity recognizer.\n",
        "\n",
        "We will use the FastText model for Czech and the CNEC corpus.\n",
        "\n",
        "## FastText\n",
        "\n",
        "FastText is a pretrained model that uses subword information. The advantage is that it assigns a vector to every sequence, so we do not have to tackle with the out-of-vocabulary (OOV problem). The downside is the size of the model.\n",
        "\n",
        "https://fasttext.cc/docs/en/crawl-vectors.html\n",
        "\n",
        "**Note for advanced students:** During training, we take only a small subset of FastText and do not bring the whole model into our NER model. This means, we do not use the advantage of the subword feature at prediction time. To solve this problem, we could do the following:\n",
        "\n",
        "1. remove the Embedding layer\n",
        "1. use the array of token embeddings as the input\n",
        "\n",
        "It makes the code slightly less readable and it makes the preprocessing of input examples slightly more complicated. You can implement it on your own.\n",
        "\n",
        "## CNEC\n",
        "\n",
        "Czech Corpus of Named Entities (https://ufal.mff.cuni.cz/cnec/cnec2.0) contains ~ 10,000 documents (usually short sentences) and a two-level classification. For the purpose of this workshop, we simplify drastically the annotation.\n",
        "1. We completely omit the nested annotations\n",
        "1. We remove some annotations (such as capitalizations)\n",
        "1. We merge many annotations to have only a few possible NER tags.\n",
        "1. We add the IOB schema to the annotations.\n",
        "\n",
        "## SumeCzech-NER\n",
        "\n",
        "Another option is to use the SumeCzech corpus together with annotations. Since it contains one million articles, the results are more promising. Moreover, the annotation of SumeCzech-NER follows already the IOB schema.\n",
        "\n",
        "Some other useful links:\n",
        "\n",
        "https://towardsdatascience.com/named-entity-recognition-ner-using-keras-bidirectional-lstm-28cd3f301f54\n",
        "\n",
        "https://docs.python.org/3/library/xml.etree.elementtree.html\n",
        "\n",
        "https://towardsdatascience.com/named-entity-recognition-ner-meeting-industrys-requirement-by-applying-state-of-the-art-deep-698d2b3b4ede\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxnjdyjuyBKq"
      },
      "source": [
        "## Install FastText and download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMoTUVpwXq-V",
        "outputId": "144c6025-e510-4a27-fec2-de2225faf144",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install fasttext"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▊                           | 10 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 20 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 30 kB 32.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 40 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 51 kB 20.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 61 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 68 kB 4.6 MB/s \n",
            "\u001b[?25hCollecting pybind11>=2.2\n",
            "  Using cached pybind11-2.8.0-py2.py3-none-any.whl (207 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext) (57.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext) (1.19.5)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp37-cp37m-linux_x86_64.whl size=3119462 sha256=73aa4928c37debe803d57b292912982477b1916b0d7ad21e004530f10d1d48dc\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/ca/bf/b020d2be95f7641801a6597a29c8f4f19e38f9c02a345bab9b\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIHlsGTlYPkZ",
        "outputId": "19fd0bb8-e20d-4f02-ad46-344a76857981",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.cs.300.bin.gz\n",
        "!gunzip cc.cs.300.bin.gz"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-06 10:47:58--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.cs.300.bin.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 104.22.75.142, 172.67.9.4, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4502843070 (4.2G) [application/octet-stream]\n",
            "Saving to: ‘cc.cs.300.bin.gz’\n",
            "\n",
            "cc.cs.300.bin.gz    100%[===================>]   4.19G  12.6MB/s    in 5m 41s  \n",
            "\n",
            "2021-10-06 10:53:40 (12.6 MB/s) - ‘cc.cs.300.bin.gz’ saved [4502843070/4502843070]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7YIBv-Lbmul",
        "outputId": "1993f71e-30b3-4355-8a95-d4985925f579",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!curl --remote-name-all https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11858/00-097C-0000-0023-1B22-8{/Czech_Named_Entity_Corpus_2.0.zip}\n",
        "!unzip Czech_Named_Entity_Corpus_2.0.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 13.2M  100 13.2M    0     0  6098k      0  0:00:02  0:00:02 --:--:-- 6098k\n",
            "Archive:  Czech_Named_Entity_Corpus_2.0.zip\n",
            "   creating: cnec2.0/\n",
            "   creating: cnec2.0/data/\n",
            "   creating: cnec2.0/data/plain/\n",
            "  inflating: cnec2.0/data/plain/named_ent.txt  \n",
            "  inflating: cnec2.0/data/plain/named_ent_dtest.txt  \n",
            "  inflating: cnec2.0/data/plain/named_ent_etest.txt  \n",
            "  inflating: cnec2.0/data/plain/named_ent_train.txt  \n",
            "   creating: cnec2.0/data/xml/\n",
            "  inflating: cnec2.0/data/xml/named_ent.xml  \n",
            "  inflating: cnec2.0/data/xml/named_ent_dtest.xml  \n",
            "  inflating: cnec2.0/data/xml/named_ent_etest.xml  \n",
            "  inflating: cnec2.0/data/xml/named_ent_train.xml  \n",
            "   creating: cnec2.0/data/treex/\n",
            "  inflating: cnec2.0/data/treex/named_ent.treex  \n",
            "  inflating: cnec2.0/data/treex/named_ent_dtest.treex  \n",
            "  inflating: cnec2.0/data/treex/named_ent_etest.treex  \n",
            "  inflating: cnec2.0/data/treex/named_ent_train.treex  \n",
            "   creating: cnec2.0/data/html/\n",
            "  inflating: cnec2.0/data/html/named_ent.html  \n",
            "  inflating: cnec2.0/data/html/named_ent_dtest.html  \n",
            "  inflating: cnec2.0/data/html/named_ent_etest.html  \n",
            "  inflating: cnec2.0/data/html/named_ent_train.html  \n",
            "   creating: cnec2.0/doc/\n",
            "  inflating: cnec2.0/doc/ne-type-hierarchy.pdf  \n",
            "  inflating: cnec2.0/doc/doc.pdf     \n",
            "  inflating: cnec2.0/doc/techrep-ne-2007.pdf  \n",
            "  inflating: cnec2.0/doc/statistics.txt  \n",
            "  inflating: cnec2.0/README          \n",
            "  inflating: cnec2.0/LICENSE         \n",
            "   creating: cnec2.0/tools/\n",
            "  inflating: cnec2.0/tools/compare_ne_outputs_v3.pl  \n",
            "  inflating: cnec2.0/tools/namedent_annotations_to_html.pl  \n",
            "  inflating: cnec2.0/tools/statistics.pl  \n",
            "  inflating: cnec2.0/tools/namedent_annotations_to_xml_simple.pl  \n",
            "   creating: cnec2.0/tools/Treex/\n",
            "   creating: cnec2.0/tools/Treex/Block/\n",
            "   creating: cnec2.0/tools/Treex/Block/Read/\n",
            "  inflating: cnec2.0/tools/Treex/Block/Read/CNEC.pm  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpOKRFF8YXVx"
      },
      "source": [
        "FASTTEXT_MODEL = 'cc.cs.300.bin'\n",
        "NER_CORPUS = 'cnec2.0/data/treex/named_ent.treex'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysCPTcNayRIn"
      },
      "source": [
        "## Simplify the tags\n",
        "\n",
        "Before proceeding, check the two-level annotation from the CNEC documentation and by observing some examples.\n",
        "\n",
        "**TASK 1** Find example of a nested annotation. Find example of an annotation you would annotate in a different way."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtVNCPXDphrY"
      },
      "source": [
        "SIMPLIFICATION_DICT1 = {'P': 'PER', 'ps': 'PER', 'pf': 'PER', 'p_': 'PER', 'pc': 'PER', 'pp': 'PER', 'pd': 'PER', 'pm': 'PER',\n",
        "                       'G': 'LOC', 'gu': 'LOC', 'gs': 'LOC', 'gc': 'LOC', 'gh': 'LOC', 'gq': 'LOC', 'gl': 'LOC', 'gr': 'LOC', 'gt': 'LOC', 'g_': 'LOC',\n",
        "                       'I': 'ORG', 'if': 'ORG', 'i_': 'ORG', 'ia': 'ORG', 'ic': 'ORG', 'io': 'ORG',\n",
        "                       'O': 'ART', 'oa': 'ART', 'or': 'ART', 'om': 'ART', 'oe': 'ART', 'o_': 'ART', 'op': 'ART',\n",
        "                       'A': 'ADDR', 'ah': 'ADDR', 'az': 'ADDR', 'a_': 'ADDR', 'at': 'ADDR',\n",
        "                       'M': 'MEDIA', 'me': 'MEDIA', 'mi': 'MEDIA', 'm_': 'MEDIA', 'mn': 'MEDIA', 'ms': 'MEDIA', \n",
        "                       'N': 'NUM', 'na': 'NUM', 'nb': 'NUM', 'nc': 'NUM', 'n_': 'NUM', 'ni': 'NUM', 'ns': 'NUM', 'no': 'NUM',\n",
        "                       'T': 'TIME', 'td': 'TIME', 'tm': 'TIME', 'ty': 'TIME', 'tf': 'TIME', 't_': 'TIME', 'th': 'TIME',\n",
        "                       '?': 'O', 'cap': 'O', 'lower': 'O', 'upper': 'O', 'f': 'FOREIGN', 'segm': 'O', 's': 'ABBR', 'C': 'BIB'}\n",
        "\n",
        "SIMPLIFICATION_DICT2 = {'P': 'PER', 'ps': 'PER', 'pf': 'PER', 'p_': 'PER', 'pc': 'PER', 'pp': 'PER', 'pd': 'PER', 'pm': 'PER',\n",
        "                       'G': 'LOC', 'gu': 'LOC', 'gs': 'LOC', 'gc': 'LOC', 'gh': 'LOC', 'gq': 'LOC', 'gl': 'LOC', 'gr': 'LOC', 'gt': 'LOC', 'g_': 'LOC',\n",
        "                       'I': 'ORG', 'if': 'ORG', 'i_': 'ORG', 'ia': 'ORG', 'ic': 'ORG', 'io': 'ORG',\n",
        "                       'O': 'O', 'oa': 'O', 'or': 'O', 'om': 'O', 'oe': 'O', 'o_': 'O', 'op': 'O',\n",
        "                       'A': 'O', 'ah': 'O', 'az': 'O', 'a_': 'O', 'at': 'O',\n",
        "                       'M': 'O', 'me': 'O', 'mi': 'O', 'm_': 'O', 'mn': 'O', 'ms': 'O', \n",
        "                       'N': 'O', 'na': 'O', 'nb': 'O', 'nc': 'O', 'n_': 'O', 'ni': 'O', 'ns': 'O', 'no': 'O',\n",
        "                       'T': 'O', 'td': 'O', 'tm': 'O', 'ty': 'O', 'tf': 'O', 't_': 'O', 'th': 'O',\n",
        "                       '?': 'O', 'cap': 'O', 'lower': 'O', 'upper': 'O', 'f': 'O', 'segm': 'O', 's': 'O', 'C': 'O'}                       \n",
        "\n",
        "SIMPLIFICATION_DICT = {'P': 'PER', 'ps': 'PER', 'pf': 'PER', 'p_': 'PER', 'pc': 'PER', 'pp': 'PER', 'pd': 'PER', 'pm': 'PER',\n",
        "                       'G': 'LOC', 'gu': 'LOC', 'gs': 'LOC', 'gc': 'LOC', 'gh': 'LOC', 'gq': 'LOC', 'gl': 'LOC', 'gr': 'LOC', 'gt': 'LOC', 'g_': 'LOC',\n",
        "                       'I': 'ORG', 'if': 'ORG', 'i_': 'ORG', 'ia': 'ORG', 'ic': 'ORG', 'io': 'ORG',\n",
        "                       'O': 'MISC', 'oa': 'MISC', 'or': 'MISC', 'om': 'MISC', 'oe': 'MISC', 'o_': 'MISC', 'op': 'MISC',\n",
        "                       'A': 'MISC', 'ah': 'MISC', 'az': 'MISC', 'a_': 'MISC', 'at': 'MISC',\n",
        "                       'M': 'MISC', 'me': 'MISC', 'mi': 'MISC', 'm_': 'MISC', 'mn': 'MISC', 'ms': 'MISC', \n",
        "                       'N': 'MISC', 'na': 'MISC', 'nb': 'MISC', 'nc': 'MISC', 'n_': 'MISC', 'ni': 'MISC', 'ns': 'MISC', 'no': 'MISC',\n",
        "                       'T': 'MISC', 'td': 'MISC', 'tm': 'MISC', 'ty': 'MISC', 'tf': 'MISC', 't_': 'MISC', 'th': 'MISC',\n",
        "                       '?': 'O', 'cap': 'O', 'lower': 'O', 'upper': 'O', 'f': 'MISC', 'segm': 'O', 's': 'MISC', 'C': 'O'}                                              "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVYj0DZsXKYN"
      },
      "source": [
        "import numpy as np\n",
        "import os, sys, re\n",
        "import time\n",
        "import fasttext\n",
        "import logging\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from tensorflow.keras import Sequential, Model, Input\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, InputLayer\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.initializers import Constant\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_8OyW00X2OD",
        "outputId": "5d4eeba1-82e6-4a13-e1c4-03e49a1ecfe1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        " # This takes ~2 mins.\n",
        " %time embeddings = fasttext.load_model(FASTTEXT_MODEL)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4.18 s, sys: 8.83 s, total: 13 s\n",
            "Wall time: 3min 14s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hdxVp7zziZV"
      },
      "source": [
        "## Parsing the CNEC\n",
        "CNEC comes in several format. In this section, we parse the XML structure to obtain a simple format: token / annotation.\n",
        "\n",
        "**Note for advanced students:** We extract also the lemma and POS tag, so you can experiment in your implementation with these additional features. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkTO7Ho0cP2H"
      },
      "source": [
        "tree = ET.parse(NER_CORPUS)\n",
        "ns = {\"pml\":\"http://ufal.mff.cuni.cz/pdt/pml/\"}\n",
        "root = tree.getroot()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHabZdIocYY4",
        "outputId": "825dce76-fc6d-4900-e358-a3e7e4f959c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sentences = root.find('pml:bundles', namespaces=ns).getchildren()\n",
        "sentences[:2]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: This method will be removed in future versions.  Use 'list(elem)' or iteration over elem instead.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<Element '{http://ufal.mff.cuni.cz/pdt/pml/}LM' at 0x7f4e2afb5c50>,\n",
              " <Element '{http://ufal.mff.cuni.cz/pdt/pml/}LM' at 0x7f4e2af552f0>]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwhMsUxWf1S4"
      },
      "source": [
        "def parse_ne(ne): # either children or children/LM\n",
        "  ner_dict = {}\n",
        "  ne_type = ne.findall('./pml:ne_type', ns)\n",
        "  ref = ne.findall('./pml:a.rf/pml:LM', ns)\n",
        "  if not ref:\n",
        "    ref = ne.findall('./pml:a.rf', ns)\n",
        "  if ne_type and ref:\n",
        "    for i, n in enumerate(ref):\n",
        "      tag = SIMPLIFICATION_DICT.get(ne_type[0].text, ne_type[0].text)\n",
        "      if tag != 'O':\n",
        "        ner_dict[n.text] = ('B' if i==0 else 'I')+'-'+tag  # IOB markup - experiment with this\n",
        "      else:\n",
        "        ner_dict[n.text] = 'O'\n",
        "  return ner_dict\n",
        "\n",
        "def parse_tokens(tokens, ner): # the a_tree element\n",
        "  ner_dict = {}\n",
        "  for ne in ner.findall('./pml:children', ns):\n",
        "      ner_dict = parse_ne(ne)\n",
        "      if not ner_dict:\n",
        "        for child in ne:\n",
        "          ner_dict.update(parse_ne(child))\n",
        "  token_dict = {}\n",
        "  for token in tokens.findall('.//pml:LM', ns):\n",
        "      token_dict[token.attrib.get('id')] = (token.find('pml:form', ns).text, token.find('pml:lemma', ns).text.split('_')[0].split('-')[0], token.find('pml:tag', ns).text[0])\n",
        "\n",
        "  return [(t[0], t[1], t[2], 'O') if k not in ner_dict.keys() else (t[0], t[1], t[2], ner_dict[k]) for k, t in token_dict.items()] "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqY3su5bezd7",
        "outputId": "e2f092dd-4b4e-480d-feb1-5e817302dba3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def parse_sentence(sentence): #\n",
        "    tokens = sentence.find('.//pml:a_tree', namespaces=ns)\n",
        "    ner = sentence.find('.//pml:n_tree', namespaces=ns)\n",
        "    markup = parse_tokens(tokens, ner)\n",
        "    return markup\n",
        "\n",
        "markup = parse_sentence(sentences[10])\n",
        "markup"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Marně', 'marně', 'D', 'O'),\n",
              " ('pak', 'pak', 'D', 'O'),\n",
              " ('argumentoval', 'argumentovat', 'V', 'O'),\n",
              " (',', ',', 'Z', 'O'),\n",
              " ('že', 'že', 'J', 'O'),\n",
              " ('Jezevec', 'jezevec', 'N', 'B-PER'),\n",
              " ('tam', 'tam', 'D', 'O'),\n",
              " ('byl', 'být', 'V', 'O'),\n",
              " ('taky', 'také', 'D', 'O'),\n",
              " ('sám', 'sám', 'P', 'O'),\n",
              " (',', ',', 'Z', 'O'),\n",
              " ('málo', 'málo', 'D', 'O'),\n",
              " ('platné', 'platný', 'A', 'O'),\n",
              " (',', ',', 'Z', 'O'),\n",
              " ('Kája', 'Kája', 'N', 'B-PER'),\n",
              " ('a', 'a', 'J', 'O'),\n",
              " ('nebyl', 'být', 'V', 'O'),\n",
              " ('soudruh', 'soudruh', 'N', 'O'),\n",
              " ('Jezevec', 'jezevec', 'N', 'B-PER'),\n",
              " (',', ',', 'Z', 'O'),\n",
              " ('dozor', 'dozor', 'N', 'O'),\n",
              " ('z', 'z', 'R', 'O'),\n",
              " ('ministerstva', 'ministerstvo', 'N', 'O'),\n",
              " ('a', 'a', 'J', 'O'),\n",
              " ('příležitostný', 'příležitostný', 'A', 'O'),\n",
              " ('milenec', 'milenec', 'N', 'O'),\n",
              " ('Vavrouškové', 'Vavroušková', 'N', 'B-PER'),\n",
              " ('Miluše', 'Miluše', 'N', 'I-PER'),\n",
              " ('.', '.', 'Z', 'O')]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_M8mO-FtGRY"
      },
      "source": [
        "data = {}\n",
        "markup = []\n",
        "num = []\n",
        "for i, sentence in enumerate(sentences):\n",
        "  p = parse_sentence(sentence)\n",
        "  markup += p\n",
        "  num += ([i]*len(p))\n",
        "data.update({'Sentence #': num, 'Word': [m[0] for m in markup], 'Lemma': [m[1] for m in markup], 'POS': [m[2] for m in markup], 'Tag': [m[3] for m in markup]})"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRUr2DZeur-E",
        "outputId": "75ea25d2-a159-496f-dc25-1a03635192ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "df = pd.DataFrame(data)\n",
        "df"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>Lemma</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Jste</td>\n",
              "      <td>být</td>\n",
              "      <td>V</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>světa</td>\n",
              "      <td>svět</td>\n",
              "      <td>N</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>znalý</td>\n",
              "      <td>znalý</td>\n",
              "      <td>A</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>muž</td>\n",
              "      <td>muž</td>\n",
              "      <td>N</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>J</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200138</th>\n",
              "      <td>8992</td>\n",
              "      <td>psala</td>\n",
              "      <td>psát</td>\n",
              "      <td>V</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200139</th>\n",
              "      <td>8992</td>\n",
              "      <td>Ellian</td>\n",
              "      <td>Ellian</td>\n",
              "      <td>X</td>\n",
              "      <td>B-PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200140</th>\n",
              "      <td>8992</td>\n",
              "      <td>Mac</td>\n",
              "      <td>Macintosh</td>\n",
              "      <td>N</td>\n",
              "      <td>I-PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200141</th>\n",
              "      <td>8992</td>\n",
              "      <td>Gregor</td>\n",
              "      <td>Gregor</td>\n",
              "      <td>N</td>\n",
              "      <td>I-PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200142</th>\n",
              "      <td>8992</td>\n",
              "      <td>!</td>\n",
              "      <td>!</td>\n",
              "      <td>Z</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200143 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Sentence #    Word      Lemma POS    Tag\n",
              "0                0    Jste        být   V      O\n",
              "1                0   světa       svět   N      O\n",
              "2                0   znalý      znalý   A      O\n",
              "3                0     muž        muž   N      O\n",
              "4                0       a          a   J      O\n",
              "...            ...     ...        ...  ..    ...\n",
              "200138        8992   psala       psát   V      O\n",
              "200139        8992  Ellian     Ellian   X  B-PER\n",
              "200140        8992     Mac  Macintosh   N  I-PER\n",
              "200141        8992  Gregor     Gregor   N  I-PER\n",
              "200142        8992       !          !   Z      O\n",
              "\n",
              "[200143 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsQbEi9F6iAr"
      },
      "source": [
        "sentences = df[\"Sentence #\"].values[-1] + 1"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekToE5dxwSjI"
      },
      "source": [
        "def get_dict_map(data, token_or_tag):\n",
        "    tok2idx = {}\n",
        "    idx2tok = {}\n",
        "    \n",
        "    if token_or_tag == 'token':\n",
        "        vocab = [''] + list(set(data['Word'].to_list()))\n",
        "    elif token_or_tag == 'lemma':\n",
        "        vocab = [''] + list(set(data['Lemma'].to_list()))\n",
        "    elif token_or_tag == 'pos':\n",
        "        vocab = [''] + list(set(data['POS'].to_list()))\n",
        "    else:\n",
        "        vocab = [''] + list(set(data['Tag'].to_list()))\n",
        "    \n",
        "    idx2tok = {idx:tok for  idx, tok in enumerate(vocab)}\n",
        "    tok2idx = {tok:idx for  idx, tok in enumerate(vocab)}\n",
        "    return tok2idx, idx2tok\n",
        "\n",
        "\n",
        "token2idx, idx2token = get_dict_map(df, 'token')\n",
        "lemma2idx, idx2lemma = get_dict_map(df, 'lemma')\n",
        "pos2idx, idx2pos = get_dict_map(df, 'pos')\n",
        "tag2idx, idx2tag = get_dict_map(df, 'tag')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhHM0cuIHwUI",
        "outputId": "75d6e804-2095-4ead-a03d-bfe4ca45a421",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tag2idx"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'': 0,\n",
              " 'B-LOC': 4,\n",
              " 'B-MISC': 8,\n",
              " 'B-ORG': 2,\n",
              " 'B-PER': 7,\n",
              " 'I-LOC': 5,\n",
              " 'I-MISC': 1,\n",
              " 'I-ORG': 6,\n",
              " 'I-PER': 9,\n",
              " 'O': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ze5Q8xiowdEW",
        "outputId": "e6f8a343-2ee9-407e-d74b-a17cb68d1de3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "df['Word_idx'] = df['Word'].map(token2idx)\n",
        "df['Tag_idx'] = df['Tag'].map(tag2idx)\n",
        "df['Lemma_idx'] = df['Lemma'].map(lemma2idx)\n",
        "df['Pos_idx'] = df['POS'].map(pos2idx)\n",
        "\n",
        "df"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>Lemma</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "      <th>Word_idx</th>\n",
              "      <th>Tag_idx</th>\n",
              "      <th>Lemma_idx</th>\n",
              "      <th>Pos_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Jste</td>\n",
              "      <td>být</td>\n",
              "      <td>V</td>\n",
              "      <td>O</td>\n",
              "      <td>28150</td>\n",
              "      <td>3</td>\n",
              "      <td>6120</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>světa</td>\n",
              "      <td>svět</td>\n",
              "      <td>N</td>\n",
              "      <td>O</td>\n",
              "      <td>32298</td>\n",
              "      <td>3</td>\n",
              "      <td>19918</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>znalý</td>\n",
              "      <td>znalý</td>\n",
              "      <td>A</td>\n",
              "      <td>O</td>\n",
              "      <td>5861</td>\n",
              "      <td>3</td>\n",
              "      <td>3401</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>muž</td>\n",
              "      <td>muž</td>\n",
              "      <td>N</td>\n",
              "      <td>O</td>\n",
              "      <td>36851</td>\n",
              "      <td>3</td>\n",
              "      <td>21129</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>J</td>\n",
              "      <td>O</td>\n",
              "      <td>51066</td>\n",
              "      <td>3</td>\n",
              "      <td>29352</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200138</th>\n",
              "      <td>8992</td>\n",
              "      <td>psala</td>\n",
              "      <td>psát</td>\n",
              "      <td>V</td>\n",
              "      <td>O</td>\n",
              "      <td>47677</td>\n",
              "      <td>3</td>\n",
              "      <td>9273</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200139</th>\n",
              "      <td>8992</td>\n",
              "      <td>Ellian</td>\n",
              "      <td>Ellian</td>\n",
              "      <td>X</td>\n",
              "      <td>B-PER</td>\n",
              "      <td>30871</td>\n",
              "      <td>7</td>\n",
              "      <td>17649</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200140</th>\n",
              "      <td>8992</td>\n",
              "      <td>Mac</td>\n",
              "      <td>Macintosh</td>\n",
              "      <td>N</td>\n",
              "      <td>I-PER</td>\n",
              "      <td>18817</td>\n",
              "      <td>9</td>\n",
              "      <td>25000</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200141</th>\n",
              "      <td>8992</td>\n",
              "      <td>Gregor</td>\n",
              "      <td>Gregor</td>\n",
              "      <td>N</td>\n",
              "      <td>I-PER</td>\n",
              "      <td>4864</td>\n",
              "      <td>9</td>\n",
              "      <td>2845</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200142</th>\n",
              "      <td>8992</td>\n",
              "      <td>!</td>\n",
              "      <td>!</td>\n",
              "      <td>Z</td>\n",
              "      <td>O</td>\n",
              "      <td>11617</td>\n",
              "      <td>3</td>\n",
              "      <td>6712</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200143 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Sentence #    Word      Lemma  ... Tag_idx Lemma_idx  Pos_idx\n",
              "0                0    Jste        být  ...       3      6120        9\n",
              "1                0   světa       svět  ...       3     19918        5\n",
              "2                0   znalý      znalý  ...       3      3401       12\n",
              "3                0     muž        muž  ...       3     21129        5\n",
              "4                0       a          a  ...       3     29352        4\n",
              "...            ...     ...        ...  ...     ...       ...      ...\n",
              "200138        8992   psala       psát  ...       3      9273        9\n",
              "200139        8992  Ellian     Ellian  ...       7     17649        6\n",
              "200140        8992     Mac  Macintosh  ...       9     25000        5\n",
              "200141        8992  Gregor     Gregor  ...       9      2845        5\n",
              "200142        8992       !          !  ...       3      6712        1\n",
              "\n",
              "[200143 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kg7JTgFZ0jSS",
        "outputId": "f867ede3-6c9e-46a7-b60b-c6ae76d9a187",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        }
      },
      "source": [
        "# Fill na\n",
        "df_fillna = df.fillna(method='ffill', axis=0)\n",
        "# Groupby and collect columns\n",
        "df_group = df_fillna.groupby(\n",
        "['Sentence #'],as_index=False\n",
        ")['Word', 'POS', 'Tag', 'Word_idx', 'Tag_idx', 'Lemma_idx', 'Pos_idx'].agg(lambda x: list(x))\n",
        "# Visualise data\n",
        "df_group.head()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "      <th>Word_idx</th>\n",
              "      <th>Tag_idx</th>\n",
              "      <th>Lemma_idx</th>\n",
              "      <th>Pos_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[Jste, světa, znalý, muž, a, víte, stejně, dob...</td>\n",
              "      <td>[V, N, A, N, J, V, D, D, J, P, Z, J, N, R, A, ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[28150, 32298, 5861, 36851, 51066, 11802, 1048...</td>\n",
              "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
              "      <td>[6120, 19918, 3401, 21129, 29352, 5344, 6053, ...</td>\n",
              "      <td>[9, 5, 12, 5, 4, 9, 7, 7, 4, 10, 1, 4, 5, 8, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>[byl, z, toho, už, vzteklý, jak, uvázaný, pes,...</td>\n",
              "      <td>[V, R, P, D, A, J, A, N, Z, J, N, R, N, P, D, ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[16371, 28760, 4837, 48912, 41486, 30100, 4582...</td>\n",
              "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
              "      <td>[6120, 16479, 25006, 28043, 23726, 17217, 2626...</td>\n",
              "      <td>[9, 8, 10, 7, 12, 4, 12, 5, 1, 4, 5, 8, 5, 10,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>[I, s, Dubenkou, ,, na, kterou, U, tygra, teď,...</td>\n",
              "      <td>[J, R, N, Z, R, P, R, N, D, V, Z, Z, Z]</td>\n",
              "      <td>[O, O, B-PER, O, O, O, B-ORG, I-ORG, O, O, O, ...</td>\n",
              "      <td>[31502, 25161, 3068, 6370, 30000, 23217, 11772...</td>\n",
              "      <td>[3, 3, 7, 3, 3, 3, 2, 6, 3, 3, 3, 3, 3]</td>\n",
              "      <td>[18237, 14460, 20771, 3709, 17162, 9645, 4705,...</td>\n",
              "      <td>[4, 8, 5, 1, 8, 10, 8, 5, 7, 9, 1, 1, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>[Hodil, si, kulovnici, přes, rameno, a, vydal,...</td>\n",
              "      <td>[V, P, N, R, N, J, V, P, R, A, A, N, R, N, Z, ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[1280, 17097, 6750, 35064, 30031, 51066, 23509...</td>\n",
              "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
              "      <td>[23386, 13555, 6092, 20121, 17180, 29352, 2252...</td>\n",
              "      <td>[9, 10, 5, 8, 5, 4, 9, 10, 8, 12, 12, 5, 8, 5,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>[Já, je, normálně, nosím, tak, \", -, a, ukázal...</td>\n",
              "      <td>[P, P, D, V, D, Z, Z, J, V, N, N, R, N, A, Z]</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
              "      <td>[34573, 20920, 2878, 45274, 14889, 10295, 3657...</td>\n",
              "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]</td>\n",
              "      <td>[11681, 19072, 1693, 16291, 8609, 5938, 1, 293...</td>\n",
              "      <td>[10, 10, 7, 9, 7, 1, 1, 4, 9, 5, 5, 8, 5, 12, 1]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Sentence #  ...                                            Pos_idx\n",
              "0           0  ...  [9, 5, 12, 5, 4, 9, 7, 7, 4, 10, 1, 4, 5, 8, 1...\n",
              "1           1  ...  [9, 8, 10, 7, 12, 4, 12, 5, 1, 4, 5, 8, 5, 10,...\n",
              "2           2  ...           [4, 8, 5, 1, 8, 10, 8, 5, 7, 9, 1, 1, 1]\n",
              "3           3  ...  [9, 10, 5, 8, 5, 4, 9, 10, 8, 12, 12, 5, 8, 5,...\n",
              "4           4  ...   [10, 10, 7, 9, 7, 1, 1, 4, 9, 5, 5, 8, 5, 12, 1]\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtnYIcrq0KCJ"
      },
      "source": [
        "## Know the data\n",
        "CNEC is composed of 8992 documents (mostly sentences). Below you can see the length histogram (in number of tokens). Most documents have between 5 and 25 tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kENM0LmQIVpn",
        "outputId": "d3a78547-02c5-4dc7-ccb3-b15cbc767920",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "%matplotlib inline\n",
        "plt.hist([len(s) for s in df_group['Word_idx']], bins=50) # sentence length histogram\n",
        "plt.show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2TfuSNv0eYv"
      },
      "source": [
        "## Train/Test Split\n",
        "Although CNEC comes with split data, we decided to split it differently. The corpus is not big enough, so it's better not to use train / dev / test but only train / dev.\n",
        "\n",
        "The output is categorical - it's a number, similar to POS - 1 is not better than 2. We need to encode such output as one-hot encoding. So, e.g. 2 is encoded as [0, 0, 1, 0, 0, 0, ... 0 ] where the length of the vector is the number of different possible categories (in our case, it depends on the level of simplification of the annotations). \n",
        "\n",
        "Since the input of a neural network is a matrix (list of example documents - sequences), we need all our data to be the same length.\n",
        "\n",
        "We use padding for this and pad all examples with zeros to the length of the longest document."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDeqr8Gl1qmj",
        "outputId": "f4e86f98-db89-455a-df11-e3b00bddec53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def get_pad_train_dev(df_group, df):\n",
        "\n",
        "    #Pad tokens (X var)    \n",
        "    tokens = df_group['Word_idx'].tolist()\n",
        "    maxlen = max([len(s) for s in df_group['Word_idx']])\n",
        "    pad_tokens = pad_sequences(tokens, maxlen=maxlen, dtype='int32', padding='post', value= token2idx[\"\"])\n",
        "\n",
        "    #Pad Tags (y var) and convert it into one hot encoding\n",
        "    tags = df_group['Tag_idx'].tolist()\n",
        "    pad_tags = pad_sequences(tags, maxlen=maxlen, dtype='int32', padding='post', value= tag2idx[\"O\"])\n",
        "    n_tags = len(tag2idx)\n",
        "    pad_tags_ = [to_categorical(i, num_classes=n_tags) for i in pad_tags]\n",
        "    \n",
        "    #Split train and dev set\n",
        "    train_tokens, dev_tokens, train_tags, dev_tags = train_test_split(pad_tokens, pad_tags_, test_size = 0.1, train_size =0.9, random_state=42)\n",
        "\n",
        "    print(\n",
        "        'train_tokens length:', len(train_tokens),\n",
        "        '\\ndev_tokens length:', len(dev_tokens),\n",
        "        '\\ntrain_tags:', len(train_tags),\n",
        "        '\\ndev_tags:', len(dev_tags),\n",
        "    )\n",
        "    \n",
        "    return np.array(train_tokens), np.array(dev_tokens), np.array(train_tags), np.array(dev_tags)\n",
        "\n",
        "train_tokens_, dev_tokens_, train_tags_, dev_tags_ = get_pad_train_dev(df_group, df)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_tokens length: 8093 \n",
            "dev_tokens length: 900 \n",
            "train_tags: 8093 \n",
            "dev_tags: 900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6B_O-4H-m8_0",
        "outputId": "e8c77cd5-93b1-4de9-c6ad-b2f45f818200",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_tokens_.shape, train_tags_.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8093, 116), (8093, 116, 10))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKI9dPBt1ObG"
      },
      "source": [
        "This is how the data can be converted back to human-readable form."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGSqX8OQM0-C",
        "outputId": "40bd3c7c-5c71-42eb-8700-4930d28e453f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "[(idx2token[x], idx2tag[np.argmax(y)]) for x, y in zip(train_tokens_[103], train_tags_[103]) if idx2token[x]]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Nejžádanější', 'O'),\n",
              " ('knihy', 'O'),\n",
              " ('minulého', 'O'),\n",
              " ('týdne', 'O'),\n",
              " ('ve', 'O'),\n",
              " ('vybraných', 'O'),\n",
              " ('knihkupectvích', 'O'),\n",
              " ('v', 'O'),\n",
              " ('okresech', 'O'),\n",
              " ('Kroměříž', 'B-LOC'),\n",
              " (',', 'O'),\n",
              " ('Uherské', 'B-LOC'),\n",
              " ('Hradiště', 'I-LOC'),\n",
              " (',', 'O'),\n",
              " ('Vsetín', 'B-LOC'),\n",
              " ('a', 'O'),\n",
              " ('Zlín', 'B-LOC'),\n",
              " (':', 'O')]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mp5Iz_f1TJm"
      },
      "source": [
        "Neural Network Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zl0mlUsA6Cj9",
        "outputId": "f7b1eee5-2f5a-49c6-a74e-9dd214e974b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "input_dim = len(list(set(df['Word'].to_list())))+1 # vocab length + padding\n",
        "output_dim = 64\n",
        "input_length = train_tokens_.shape[1] # max example length\n",
        "n_tags = len(tag2idx)\n",
        "print('input_dim: ', input_dim, '\\noutput_dim: ', output_dim, '\\ninput_length: ', input_length, '\\nn_tags: ', n_tags)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_dim:  51082 \n",
            "output_dim:  64 \n",
            "input_length:  116 \n",
            "n_tags:  10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJtZKXo8t9RF",
        "outputId": "a7d97bb9-ef01-4ea5-8f89-b5154a0c8664",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Prepare embedding matrix\n",
        "hits = misses = 0 # in case of FastText all tokens should be covered\n",
        "embedding_matrix = np.zeros((len(token2idx), embeddings.get_dimension()))\n",
        "for word, i in token2idx.items():\n",
        "    embedding_vector = embeddings[word]\n",
        "    if embedding_vector is not None:\n",
        "        # Words not found in embedding index will be all-zeros.\n",
        "        # This includes the representation for \"padding\" and \"OOV\"\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        hits += 1\n",
        "    else:\n",
        "        misses += 1\n",
        "print(\"Converted %d words (%d misses)\" % (hits, misses))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted 51082 words (0 misses)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdYg6eBq3vWR"
      },
      "source": [
        "## Neural Network Architecture\n",
        "\n",
        "We use BiLSTM & LSTM with dropouts. You can experiment with this. A larger network does not always bring better results. \n",
        "\n",
        "For the output layer, we use softmax and categorical crossentropy loss - this is the most suitable setting for categorization tasks.\n",
        "\n",
        "In the Embedding layer, we use the FastText weights as inputs. \n",
        "\n",
        "Since the sequences are padded with zeros, it is extremely easy for the net to learn these paddings. On the other hand, this information is not useful in the evaluation. For this reason, we use the masking of zeros, so they do not contribute to the evaluation calculation. (If you switch ``mask_zero`` to ``False``, your net will have 99% accuracy without being better than a masked net.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbuQe5Aq8voX",
        "outputId": "5bfcc402-fa03-47e1-9256-22af6427ea07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "# Add Embedding layer\n",
        "model.add(Embedding(input_dim=input_dim, output_dim=embeddings.get_dimension(), input_length=input_length, embeddings_initializer=Constant(embedding_matrix), trainable=True, mask_zero=True))\n",
        "#model.add(Embedding(input_dim=input_dim, output_dim=output_dim, input_length=input_length, trainable=True, mask_zero=True))\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "# Add BiLSTM\n",
        "model.add(Bidirectional(LSTM(units=output_dim*2, return_sequences=True), merge_mode = 'concat'))\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(units=output_dim, return_sequences=True))\n",
        "\n",
        "# Add timeDistributed Layer\n",
        "model.add(TimeDistributed(Dense(n_tags, activation=\"softmax\")))\n",
        "\n",
        "#Optimiser \n",
        "adam = Adam(lr=0.005, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "#model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 116, 300)          15324600  \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 116, 300)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 116, 256)          439296    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 116, 256)          0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 116, 64)           82176     \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 116, 10)           650       \n",
            "=================================================================\n",
            "Total params: 15,846,722\n",
            "Trainable params: 15,846,722\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvagsJDk9LRU",
        "outputId": "8693f7c4-012e-4495-ea8f-9eef0dac4625",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        }
      },
      "source": [
        "%matplotlib inline\n",
        "results = pd.DataFrame()\n",
        "plot_model(model)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WLSOVzEJ1uD"
      },
      "source": [
        "## Setting the training parameters\n",
        "\n",
        "It is difficult to set all the hyperparameters (parameters of the net + parameters of the training) to perform the best. However, what is worth trying:\n",
        "1. learning rate: larger numbers can speed up the learning but also can cause divergence\n",
        "1. number of epochs: If you observe val_loss/val_accuracy diverge - reduce the number of epochs to prevent overfitting. If the results are not good enough, try to increase the number of epochs - maybe the training didn't finish.\n",
        "1. validation_split: Here, we would need more training examples (we observe a gap between accuracy and val_accuracy), so every example counts. Try increasing the number of training examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AYaxUhs9Hb2",
        "outputId": "63de5438-7a94-4efd-94a1-890321895ec9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Training: It takes several minutes.\n",
        "hist = model.fit(train_tokens_, train_tags_, batch_size=64, verbose=1, epochs=5, validation_split=0.1)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "114/114 [==============================] - 179s 1s/step - loss: 0.1210 - accuracy: 0.8273 - val_loss: 0.0720 - val_accuracy: 0.8847\n",
            "Epoch 2/5\n",
            "114/114 [==============================] - 162s 1s/step - loss: 0.0524 - accuracy: 0.9116 - val_loss: 0.0530 - val_accuracy: 0.9152\n",
            "Epoch 3/5\n",
            "114/114 [==============================] - 162s 1s/step - loss: 0.0268 - accuracy: 0.9545 - val_loss: 0.0510 - val_accuracy: 0.9217\n",
            "Epoch 4/5\n",
            "114/114 [==============================] - 161s 1s/step - loss: 0.0169 - accuracy: 0.9717 - val_loss: 0.0546 - val_accuracy: 0.9249\n",
            "Epoch 5/5\n",
            "114/114 [==============================] - 164s 1s/step - loss: 0.0111 - accuracy: 0.9815 - val_loss: 0.0584 - val_accuracy: 0.9200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8NzC9zg2yjJ"
      },
      "source": [
        "## Sample predictions on the train set\n",
        "\n",
        "Below, you can see predictions on the train set. Not surprisingly, they are correct.\n",
        "\n",
        "**TASK 2** Modify the code to display dev set predictions. Comment on what you see.\n",
        "\n",
        "**OPTIONAL TASK** Evaluate the network on the dev set. What entities are easy to recognize? Which are hard?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INV0Z89OVY3z"
      },
      "source": [
        "def print_predictions(tokens, tags, count=10):\n",
        "  i = 0\n",
        "\n",
        "  for sample, annotation in zip(tokens, tags):\n",
        "    ex=sample.reshape((1, sample.shape[0]))\n",
        "    prediction = model.predict(ex)\n",
        "    ner = np.squeeze(np.argmax(prediction, axis=-1)[:len(sample)])\n",
        "    print([(idx2token[x], idx2tag[np.argmax(y)], idx2tag[z]) for x, y, z in zip(sample, annotation, ner) if idx2token[x]])\n",
        "    i += 1\n",
        "    if i == count:\n",
        "      break"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9t3iofewWfK-",
        "outputId": "1c99f233-6d7d-47e1-e1df-aa9669b79499",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Predicting for train set\")\n",
        "print_predictions(train_tokens_, train_tags_, 10)\n",
        "print(\"Predicting for test set\")\n",
        "print_predictions(dev_tokens_, dev_tags_, 10)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting for train set\n",
            "[('A', 'O', 'O'), ('s', 'O', 'O'), ('velkým', 'O', 'O'), ('zájmem', 'O', 'O'), ('si', 'O', 'O'), ('prohlížel', 'O', 'O'), (',', 'O', 'O'), ('jak', 'O', 'O'), ('slavná', 'O', 'O'), ('osoba', 'O', 'O'), ('před', 'O', 'O'), ('ním', 'O', 'O'), ('vypadá', 'O', 'O'), ('.', 'O', 'O')]\n",
            "[('Ne', 'O', 'O'), (',', 'O', 'O'), ('to', 'O', 'O'), ('je', 'O', 'O'), ('špatná', 'O', 'O'), ('odpověď', 'O', 'O'), ('.', 'O', 'O')]\n",
            "[('Jakmile', 'O', 'O'), ('se', 'O', 'O'), ('od', 'O', 'O'), ('něho', 'O', 'O'), ('dílo', 'O', 'O'), ('odpoutá', 'O', 'O'), (',', 'O', 'O'), ('dá', 'O', 'O'), ('znovu', 'O', 'O'), ('zaznít', 'O', 'O'), ('jen', 'O', 'O'), ('nepatrně', 'O', 'O'), ('utlumenému', 'O', 'O'), ('hlasu', 'O', 'O'), ('duše', 'O', 'O'), (',', 'O', 'O'), ('jež', 'O', 'O'), ('byla', 'O', 'O'), ('provždy', 'O', 'O'), ('zbavena', 'O', 'O'), ('naděje', 'O', 'O'), ('.', 'O', 'O')]\n",
            "[('Takové', 'O', 'O'), ('umytí', 'O', 'O'), ('čas', 'O', 'O'), ('od', 'O', 'O'), ('času', 'O', 'O'), ('neškodí', 'O', 'O'), (',', 'O', 'O'), ('ba', 'O', 'O'), ('má', 'O', 'O'), ('i', 'O', 'O'), ('nejeden', 'O', 'O'), ('klad', 'O', 'O'), ('!', 'O', 'O')]\n",
            "[('Zatímco', 'O', 'O'), ('Sukův', 'B-PER', 'B-PER'), ('Klavírní', 'B-MISC', 'B-MISC'), ('kvartet', 'I-MISC', 'I-MISC'), ('a', 'I-MISC', 'I-MISC'), ('moll', 'I-MISC', 'I-MISC'), ('vznikl', 'O', 'O'), ('ve', 'O', 'O'), ('třídě', 'O', 'O'), ('Antonína', 'B-PER', 'B-PER'), ('Dvořáka', 'I-PER', 'I-PER'), (',', 'O', 'O'), ('podnítilo', 'O', 'O'), ('Dvořákův', 'B-PER', 'B-PER'), ('Klavírní', 'B-MISC', 'B-MISC'), ('kvartet', 'I-MISC', 'I-MISC'), ('Es', 'I-MISC', 'I-MISC'), ('dur', 'I-MISC', 'I-MISC'), ('čtyřleté', 'O', 'O'), ('naléhání', 'O', 'O'), ('nakladatele', 'O', 'O'), ('Simrocka', 'B-PER', 'B-PER'), ('.', 'O', 'O')]\n",
            "[('To', 'O', 'O'), ('proto', 'O', 'O'), (',', 'O', 'O'), ('abychom', 'O', 'O'), ('nástrahu', 'O', 'O'), ('se', 'O', 'O'), ('splávkem', 'O', 'O'), ('dohodili', 'O', 'O'), ('i', 'O', 'O'), ('do', 'O', 'O'), ('vzdálenějších', 'O', 'O'), ('míst', 'O', 'O'), ('.', 'O', 'O')]\n",
            "[('Bylo', 'O', 'O'), ('jich', 'O', 'O'), ('mnoho', 'O', 'O'), ('a', 'O', 'O'), ('každý', 'O', 'O'), ('byl', 'O', 'O'), ('něčím', 'O', 'O'), ('zvláštní', 'O', 'O'), ('-', 'O', 'O'), ('způsoby', 'O', 'O'), ('jednání', 'O', 'O'), (',', 'O', 'O'), ('projevem', 'O', 'O'), ('i', 'O', 'O'), ('vzhledem', 'O', 'O'), ('.', 'O', 'O')]\n",
            "[('29', 'B-MISC', 'B-MISC'), ('.', 'I-MISC', 'I-MISC'), ('3', 'I-MISC', 'I-MISC'), ('.', 'I-MISC', 'I-MISC'), ('1899', 'I-MISC', 'I-MISC'), ('se', 'O', 'O'), ('v', 'O', 'O'), ('chudé', 'O', 'O'), ('rolnické', 'O', 'O'), ('rodině', 'O', 'O'), ('poblíž', 'O', 'O'), ('abchazského', 'O', 'O'), ('Suchumi', 'B-LOC', 'B-LOC'), ('narodil', 'O', 'O'), ('LAVRENTIJ', 'B-PER', 'B-PER'), ('PAVLOVIČ', 'I-PER', 'I-PER'), ('BERIJA', 'I-PER', 'I-PER'), ('.', 'O', 'O')]\n",
            "[('Mezi', 'O', 'O'), ('příznivci', 'O', 'O'), ('oddílu', 'O', 'O'), ('se', 'O', 'O'), ('spekuluje', 'O', 'O'), ('o', 'O', 'O'), ('možnosti', 'O', 'O'), ('stěhování', 'O', 'O'), ('oddílu', 'O', 'O'), ('po', 'O', 'O'), ('sezoně', 'O', 'O'), ('do', 'O', 'O'), ('Brna', 'B-LOC', 'B-LOC'), ('anebo', 'O', 'O'), ('do', 'O', 'O'), ('Olomouce', 'B-LOC', 'B-LOC'), ('.', 'O', 'O')]\n",
            "[('Byl', 'O', 'O'), ('z', 'O', 'O'), ('toho', 'O', 'O'), ('naprosto', 'O', 'O'), ('vyveden', 'O', 'O'), ('z', 'O', 'O'), ('míry', 'O', 'O'), ('.', 'O', 'O')]\n",
            "Predicting for test set\n",
            "[('Válka', 'O', 'O'), ('s', 'O', 'O'), ('nepřáteli', 'O', 'I-MISC'), ('Boha', 'B-PER', 'B-PER'), ('je', 'O', 'O'), ('pro', 'O', 'O'), ('ni', 'O', 'O'), ('náboženskou', 'O', 'O'), ('povinností', 'O', 'O'), ('a', 'O', 'O'), ('stát', 'O', 'O'), ('podobný', 'O', 'O'), ('Írán', 'B-LOC', 'B-PER'), ('ajatolláha', 'O', 'O'), ('Chomejního', 'B-PER', 'O'), ('cílem', 'O', 'O'), ('.', 'O', 'O')]\n",
            "[('TÁBOR', 'B-LOC', 'O'), ('-', 'O', 'O'), ('Na', 'O', 'O'), ('operačním', 'O', 'O'), ('sále', 'O', 'O'), ('Okresní', 'B-ORG', 'B-ORG'), ('nemocnice', 'I-ORG', 'I-ORG'), ('v', 'I-ORG', 'I-ORG'), ('Táboře', 'I-ORG', 'I-ORG'), ('z', 'O', 'O'), ('důvodu', 'O', 'O'), ('značného', 'O', 'O'), ('opotřebování', 'O', 'O'), ('naráz', 'O', 'O'), ('odešly', 'O', 'O'), ('dva', 'O', 'O'), ('rentgenologické', 'O', 'O'), ('přístroje.', 'O', 'O')]\n",
            "[('K', 'O', 'O'), ('jejich', 'O', 'O'), ('destrukci', 'O', 'O'), ('je', 'O', 'O'), ('potřebná', 'O', 'O'), ('teplota', 'O', 'O'), ('kolem', 'O', 'O'), ('1500', 'B-MISC', 'B-MISC'), ('oC', 'B-MISC', 'B-MISC'), ('.', 'O', 'O')]\n",
            "[('Referenční', 'O', 'O'), ('hodnoty', 'O', 'O'), ('cO2', 'B-MISC', 'O'), (':', 'O', 'O')]\n",
            "[('\"', 'O', 'O'), ('30', 'B-MISC', 'B-MISC'), ('objektů', 'O', 'O'), (',', 'O', 'O'), ('jako', 'O', 'O'), ('na', 'O', 'O'), ('běžícím', 'O', 'O'), ('pásu', 'O', 'O'), ('\"', 'O', 'O')]\n",
            "[('Na', 'O', 'O'), ('návrh', 'O', 'O'), ('bývalého', 'O', 'O'), ('člena', 'O', 'O'), ('představenstva', 'O', 'O'), ('Miroslava', 'B-PER', 'B-PER'), ('Ševčíka', 'I-PER', 'I-PER'), ('však', 'O', 'O'), ('krajský', 'O', 'O'), ('obchodní', 'O', 'O'), ('soud', 'O', 'O'), ('v', 'O', 'O'), ('polovině', 'O', 'O'), ('července', 'O', 'B-MISC'), ('vydal', 'O', 'O'), ('předběžné', 'O', 'O'), ('opatření', 'O', 'O'), (',', 'O', 'O'), ('v', 'O', 'O'), ('němž', 'O', 'O'), ('se', 'O', 'O'), ('vyslovil', 'O', 'O'), (',', 'O', 'O'), ('že', 'O', 'O'), ('svolání', 'O', 'O'), ('mimořádné', 'O', 'O'), ('hromady', 'O', 'O'), ('je', 'O', 'O'), ('neplatné', 'O', 'O'), ('.', 'O', 'O')]\n",
            "[('Snažila', 'O', 'O'), ('se', 'O', 'O'), ('proti', 'O', 'O'), ('tomu', 'O', 'O'), ('bojovat', 'O', 'O'), (',', 'O', 'O'), ('stejně', 'O', 'O'), ('jako', 'O', 'O'), ('bojovala', 'O', 'O'), ('proti', 'O', 'O'), ('pocitu', 'O', 'O'), ('ponížení', 'O', 'O'), ('.', 'O', 'O')]\n",
            "[('U', 'O', 'O'), ('zaměstnaných', 'O', 'O'), ('připadá', 'O', 'O'), ('na', 'O', 'O'), ('osoby', 'O', 'O'), ('ve', 'O', 'O'), ('věku', 'O', 'O'), ('do', 'O', 'O'), ('45', 'B-MISC', 'B-MISC'), ('let', 'O', 'O'), ('v', 'O', 'O'), ('tomto', 'O', 'O'), ('kraji', 'O', 'O'), ('63,5', 'B-MISC', 'B-MISC'), ('%', 'O', 'O'), ('(', 'O', 'O'), ('celostátně', 'O', 'O'), ('61,3', 'B-MISC', 'B-MISC'), ('%', 'O', 'O'), (')', 'O', 'O'), (',', 'O', 'O'), ('u', 'O', 'O'), ('nezaměstnaných', 'O', 'O'), ('73,4', 'B-MISC', 'B-MISC'), ('%', 'O', 'O'), ('(', 'O', 'O'), ('celostátně', 'O', 'O'), ('72,9', 'B-MISC', 'B-MISC'), ('%', 'O', 'O'), (')', 'O', 'O'), ('.', 'O', 'O')]\n",
            "[('Utrpení', 'O', 'O'), ('bylo', 'O', 'O'), ('považováno', 'O', 'O'), ('za', 'O', 'O'), ('součást', 'O', 'O'), ('lidské', 'O', 'O'), ('přirozenosti', 'O', 'O'), (':', 'O', 'O'), ('když', 'O', 'O'), ('se', 'O', 'O'), ('lidé', 'O', 'O'), ('stále', 'O', 'O'), ('více', 'O', 'O'), ('zabývali', 'O', 'O'), ('svou', 'O', 'O'), ('duší', 'O', 'O'), (',', 'O', 'O'), ('zanedbávali', 'O', 'O'), ('své', 'O', 'O'), ('tělo', 'O', 'O'), (',', 'O', 'O'), ('medicína', 'O', 'O'), ('se', 'O', 'O'), ('stala', 'O', 'O'), ('předmětem', 'O', 'O'), ('víry', 'O', 'O'), ('a', 'O', 'O'), ('recepty', 'O', 'O'), ('se', 'O', 'O'), ('změnily', 'O', 'O'), ('v', 'O', 'O'), ('modlitby', 'O', 'O'), ('.', 'O', 'O')]\n",
            "[('Kvůli', 'O', 'O'), ('atentátu', 'O', 'O'), ('přišla', 'O', 'O'), ('o', 'O', 'O'), ('dalšího', 'O', 'O'), ('člena', 'O', 'O'), ('rodiny', 'O', 'O'), ('-', 'O', 'O'), ('o', 'O', 'O'), ('švagra', 'O', 'O'), ('Roberta', 'B-PER', 'B-PER'), (',', 'O', 'O'), ('a', 'O', 'O'), ('začala', 'O', 'O'), ('se', 'O', 'O'), ('bát', 'O', 'O'), (',', 'O', 'O'), ('že', 'O', 'O'), ('další', 'O', 'O'), ('na', 'O', 'O'), ('řadě', 'O', 'O'), ('jsou', 'O', 'O'), ('její', 'O', 'O'), ('děti', 'O', 'O'), ('.', 'O', 'O')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWGRKtdrX3Fi"
      },
      "source": [
        "def print_wrong_predictions(tokens, tags, count=10):\n",
        "  i = 0\n",
        "\n",
        "  for sample, annotation in zip(tokens, tags):\n",
        "    ex=sample.reshape((1, sample.shape[0]))\n",
        "    prediction = model.predict(ex)\n",
        "    ner = np.squeeze(np.argmax(prediction, axis=-1)[:len(sample)])\n",
        "    print([(idx2token[x], idx2tag[np.argmax(y)], idx2tag[z]) for x, y, z in zip(sample, annotation, ner) if (idx2token[x] and idx2tag[np.argmax(y)] != idx2tag[z])])\n",
        "    i += 1\n",
        "    if i == count:\n",
        "      break"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhwy9vVmYV97",
        "outputId": "cfba4be2-1439-4f8f-8bad-5fad10096faf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print_wrong_predictions(dev_tokens_, dev_tags_, 10)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('nepřáteli', 'O', 'I-MISC'), ('Írán', 'B-LOC', 'B-PER'), ('Chomejního', 'B-PER', 'O')]\n",
            "[('TÁBOR', 'B-LOC', 'O')]\n",
            "[]\n",
            "[('cO2', 'B-MISC', 'O')]\n",
            "[]\n",
            "[('července', 'O', 'B-MISC')]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAcKba2M3J3M"
      },
      "source": [
        "## Try on your own sentences\n",
        "\n",
        "Some entities are easier to recognize than others.\n",
        "\n",
        "**TASK 3** Experiment on sentences with different types of entities, OOVs etc. Comment on what you see."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXkccVbftiJJ",
        "outputId": "8f7fbbd1-83a2-4b61-b6a4-e26140a82321",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "my_sentence = \"Ahoj , já jsem Pepa Tichošlápek z Brna .\"\n",
        "encoded = [token2idx.get(t, 0) for t in my_sentence.split()] + [0] * input_length\n",
        "print(\"OOV:\", [t for t in my_sentence.split() if t not in token2idx])\n",
        "encoded = encoded[:input_length]\n",
        "\n",
        "sample = np.array(encoded).reshape((1, input_length))\n",
        "prediction = model.predict(sample)\n",
        "ner = np.squeeze(np.argmax(prediction, axis=-1)[:len(my_sentence.split())])\n",
        "print([(t, idx2tag[n]) for t, n in zip(my_sentence.split(), ner)])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOV: ['Tichošlápek']\n",
            "[('Ahoj', 'O'), (',', 'O'), ('já', 'O'), ('jsem', 'O'), ('Pepa', 'B-PER'), ('Tichošlápek', 'B-PER'), ('z', 'O'), ('Brna', 'B-LOC'), ('.', 'O')]\n"
          ]
        }
      ]
    }
  ]
}